{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3OTB1uZ8vFS",
        "outputId": "846808c4-96da-4d5c-e751-532c5442043b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.9/56.9 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q flwr[\"simulation\"] tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "53jgRvWPBpxE"
      },
      "outputs": [],
      "source": [
        "from typing import Dict, List, Tuple\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import flwr as fl\n",
        "from flwr.common import Metrics\n",
        "from flwr.simulation.ray_transport.utils import enable_tf_gpu_growth\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from keras.models import load_model, Sequential\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "import keras\n",
        "from keras.layers import Dense\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from functools import partial\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "np.random.seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8S0T2p49Kfaq",
        "outputId": "bd8e5bc6-8922-48d5-c8c1-49231b407ea7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDRPjFbuoIiP",
        "outputId": "bf3cbb70-62e2-48c1-8eb8-05ccabe33398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppj2_IBjQ0zQ"
      },
      "outputs": [],
      "source": [
        "ddos = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/DDoS_client_1.csv')\n",
        "webbased = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/WebBased_client_2.csv')\n",
        "# spoofing = pd.read_csv('/content/Spoofing_client_3.csv')\n",
        "# recon = pd.read_csv('/content/Recon_client_4.csv')\n",
        "dos = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/Dos_client_5.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "HwUj_uYsNB3R",
        "outputId": "c95fba49-69fe-439f-fd5f-5d2137629ea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ddos \n",
            " (519478, 34)\n",
            "web based \n",
            " (34306, 34)\n",
            "dos \n",
            " (234299, 34)\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "ddos"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-24337d41-b2b5-4714-8f05-de3125bbf87d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>flow_duration</th>\n",
              "      <th>Header_Length</th>\n",
              "      <th>Protocol Type</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Rate</th>\n",
              "      <th>Srate</th>\n",
              "      <th>Drate</th>\n",
              "      <th>fin_flag_number</th>\n",
              "      <th>syn_flag_number</th>\n",
              "      <th>rst_flag_number</th>\n",
              "      <th>...</th>\n",
              "      <th>TCP</th>\n",
              "      <th>UDP</th>\n",
              "      <th>ARP</th>\n",
              "      <th>ICMP</th>\n",
              "      <th>IPv</th>\n",
              "      <th>LLC</th>\n",
              "      <th>Tot sum</th>\n",
              "      <th>Tot size</th>\n",
              "      <th>IAT</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>64.00</td>\n",
              "      <td>18.961634</td>\n",
              "      <td>18.961634</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>567.00</td>\n",
              "      <td>54.00</td>\n",
              "      <td>8.334452e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>64.00</td>\n",
              "      <td>17.339716</td>\n",
              "      <td>17.339716</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>567.00</td>\n",
              "      <td>54.00</td>\n",
              "      <td>8.307208e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>64.00</td>\n",
              "      <td>37.503053</td>\n",
              "      <td>37.503053</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>567.00</td>\n",
              "      <td>54.00</td>\n",
              "      <td>8.333169e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.00</td>\n",
              "      <td>6.00</td>\n",
              "      <td>64.00</td>\n",
              "      <td>32.283211</td>\n",
              "      <td>32.283211</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>567.00</td>\n",
              "      <td>54.00</td>\n",
              "      <td>8.309439e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.103837</td>\n",
              "      <td>34012.30</td>\n",
              "      <td>16.78</td>\n",
              "      <td>63.79</td>\n",
              "      <td>7069.744495</td>\n",
              "      <td>7069.744495</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>557.76</td>\n",
              "      <td>51.80</td>\n",
              "      <td>8.312387e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519473</th>\n",
              "      <td>0.070781</td>\n",
              "      <td>21825.00</td>\n",
              "      <td>17.00</td>\n",
              "      <td>64.00</td>\n",
              "      <td>6162.508840</td>\n",
              "      <td>6162.508840</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>525.00</td>\n",
              "      <td>50.00</td>\n",
              "      <td>8.310310e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519474</th>\n",
              "      <td>0.003539</td>\n",
              "      <td>12.05</td>\n",
              "      <td>1.25</td>\n",
              "      <td>63.23</td>\n",
              "      <td>39.502487</td>\n",
              "      <td>39.502487</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>9457.48</td>\n",
              "      <td>905.41</td>\n",
              "      <td>8.324982e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519475</th>\n",
              "      <td>0.831719</td>\n",
              "      <td>105.84</td>\n",
              "      <td>6.00</td>\n",
              "      <td>64.00</td>\n",
              "      <td>1.584386</td>\n",
              "      <td>1.584386</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>567.00</td>\n",
              "      <td>54.00</td>\n",
              "      <td>8.336248e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519476</th>\n",
              "      <td>0.001487</td>\n",
              "      <td>54.62</td>\n",
              "      <td>6.00</td>\n",
              "      <td>63.77</td>\n",
              "      <td>10.497196</td>\n",
              "      <td>10.497196</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>567.56</td>\n",
              "      <td>54.04</td>\n",
              "      <td>8.334916e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519477</th>\n",
              "      <td>0.233115</td>\n",
              "      <td>17027.50</td>\n",
              "      <td>16.83</td>\n",
              "      <td>63.36</td>\n",
              "      <td>1519.982774</td>\n",
              "      <td>1519.982774</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>526.40</td>\n",
              "      <td>50.10</td>\n",
              "      <td>8.310644e+07</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>519478 rows × 34 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24337d41-b2b5-4714-8f05-de3125bbf87d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-24337d41-b2b5-4714-8f05-de3125bbf87d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-24337d41-b2b5-4714-8f05-de3125bbf87d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-452d6b7b-b6e7-44e3-bb61-b06b178cdc87\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-452d6b7b-b6e7-44e3-bb61-b06b178cdc87')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-452d6b7b-b6e7-44e3-bb61-b06b178cdc87 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_09fd5827-5b7a-4ddd-93f7-00851e9b1ea2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('ddos')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_09fd5827-5b7a-4ddd-93f7-00851e9b1ea2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('ddos');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        flow_duration  Header_Length  Protocol Type  Duration         Rate  \\\n",
              "0            0.000000          54.00           6.00     64.00    18.961634   \n",
              "1            0.000000          54.00           6.00     64.00    17.339716   \n",
              "2            0.000000          54.00           6.00     64.00    37.503053   \n",
              "3            0.000000          54.00           6.00     64.00    32.283211   \n",
              "4            0.103837       34012.30          16.78     63.79  7069.744495   \n",
              "...               ...            ...            ...       ...          ...   \n",
              "519473       0.070781       21825.00          17.00     64.00  6162.508840   \n",
              "519474       0.003539          12.05           1.25     63.23    39.502487   \n",
              "519475       0.831719         105.84           6.00     64.00     1.584386   \n",
              "519476       0.001487          54.62           6.00     63.77    10.497196   \n",
              "519477       0.233115       17027.50          16.83     63.36  1519.982774   \n",
              "\n",
              "              Srate  Drate  fin_flag_number  syn_flag_number  rst_flag_number  \\\n",
              "0         18.961634    0.0              1.0              0.0              1.0   \n",
              "1         17.339716    0.0              0.0              0.0              0.0   \n",
              "2         37.503053    0.0              0.0              0.0              0.0   \n",
              "3         32.283211    0.0              0.0              1.0              0.0   \n",
              "4       7069.744495    0.0              0.0              0.0              0.0   \n",
              "...             ...    ...              ...              ...              ...   \n",
              "519473  6162.508840    0.0              0.0              0.0              0.0   \n",
              "519474    39.502487    0.0              0.0              0.0              0.0   \n",
              "519475     1.584386    0.0              0.0              1.0              0.0   \n",
              "519476    10.497196    0.0              1.0              0.0              1.0   \n",
              "519477  1519.982774    0.0              0.0              0.0              0.0   \n",
              "\n",
              "        ...  TCP  UDP  ARP  ICMP  IPv  LLC  Tot sum  Tot size           IAT  \\\n",
              "0       ...  1.0  0.0  0.0   0.0  1.0  1.0   567.00     54.00  8.334452e+07   \n",
              "1       ...  1.0  0.0  0.0   0.0  1.0  1.0   567.00     54.00  8.307208e+07   \n",
              "2       ...  1.0  0.0  0.0   0.0  1.0  1.0   567.00     54.00  8.333169e+07   \n",
              "3       ...  1.0  0.0  0.0   0.0  1.0  1.0   567.00     54.00  8.309439e+07   \n",
              "4       ...  0.0  1.0  0.0   0.0  1.0  1.0   557.76     51.80  8.312387e+07   \n",
              "...     ...  ...  ...  ...   ...  ...  ...      ...       ...           ...   \n",
              "519473  ...  0.0  1.0  0.0   0.0  1.0  1.0   525.00     50.00  8.310310e+07   \n",
              "519474  ...  0.0  0.0  0.0   1.0  1.0  1.0  9457.48    905.41  8.324982e+07   \n",
              "519475  ...  1.0  0.0  0.0   0.0  1.0  1.0   567.00     54.00  8.336248e+07   \n",
              "519476  ...  1.0  0.0  0.0   0.0  1.0  1.0   567.56     54.04  8.334916e+07   \n",
              "519477  ...  0.0  1.0  0.0   0.0  1.0  1.0   526.40     50.10  8.310644e+07   \n",
              "\n",
              "        label  \n",
              "0           1  \n",
              "1           1  \n",
              "2           1  \n",
              "3           1  \n",
              "4           1  \n",
              "...       ...  \n",
              "519473      1  \n",
              "519474      1  \n",
              "519475      1  \n",
              "519476      1  \n",
              "519477      1  \n",
              "\n",
              "[519478 rows x 34 columns]"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(f\"ddos \\n {ddos.shape}\")\n",
        "print(f\"web based \\n {webbased.shape}\")\n",
        "print(f\"dos \\n {dos.shape}\")\n",
        "# print(f\"spoofing \\n {spoofing.shape}\")\n",
        "# print(f\"recon \\n {recon.shape}\") # I have taken the reconnaince out\n",
        "\n",
        "ddos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B_5C89E1Aj0",
        "outputId": "c94cd419-396d-4f05-f7e3-1f7f3d1e3dab"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/imblearn/utils/_validation.py:313: UserWarning: After over-sampling, the number of samples (210944) in class 0 will be larger than the number of samples in the majority class (class #1 -> 189805)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "file_paths = [\n",
        "    '/content/drive/MyDrive/Colab Notebooks/datasets/DDoS_client_1.csv',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/datasets/WebBased_client_2.csv',\n",
        "    # '/content/Spoofing_client_3.csv',\n",
        "    # '/content/Recon_client_4.csv',\n",
        "    '/content/drive/MyDrive/Colab Notebooks/datasets/Dos_client_5.csv'\n",
        "]\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "global_X_train, global_y_train = [], []\n",
        "global_X_, global_y_ = [], []\n",
        "\n",
        "# Load datasets and split into global training and global test sets\n",
        "for file_path in file_paths:\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    df = shuffle(df).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "    # Split the dataset into features (X) and target variable (y)\n",
        "    # Assuming the last column is the target variable\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "\n",
        "    # Split into global training and global test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train = scaler.fit_transform(X_train)\n",
        "    X_test = scaler.transform(X_test)\n",
        "\n",
        "\n",
        "    if '/content/drive/MyDrive/Colab Notebooks/datasets/Dos_client_5.csv' in file_path:\n",
        "      # Assume X_train and y_train are your data\n",
        "      sm = SMOTE(sampling_strategy={0: 210944}, random_state=42)\n",
        "      X_res, y_res = sm.fit_resample(X_train, y_train)\n",
        "      X_train = X_res\n",
        "      y_train = y_res\n",
        "\n",
        "    # Append the global training and global test sets to the respective lists\n",
        "    global_X_train.append(X_train)\n",
        "    global_y_train.append(y_train)\n",
        "\n",
        "    global_X_.append(X_test)\n",
        "    global_y_.append(y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te5EbGaaQ2D2",
        "outputId": "1f82fe4d-f69d-48f7-800b-3324d037dd06"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Global test X shape: (78809, 33)\n",
            "Global test y shape: (78809,)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([[-0.08841058, -0.07203763,  2.07750965, ..., -0.1829034 ,\n",
              "        -0.19767222, -0.00729937],\n",
              "       [-0.09902586, -0.12937802, -0.15122833, ..., -0.1866193 ,\n",
              "        -0.19261828, -0.00847783],\n",
              "       [-0.09902586, -0.12937123, -0.12894095, ..., -0.17324642,\n",
              "        -0.18303486, -0.00999013],\n",
              "       ...,\n",
              "       [-0.03878092, -0.30881091, -0.6927967 , ..., -0.46591712,\n",
              "        -0.48375835, -0.00617884],\n",
              "       [ 0.31012373, -0.25075305, -0.6927967 , ...,  0.24307284,\n",
              "        -0.30469238,  3.16257515],\n",
              "       [ 0.86780388,  0.32507698, -0.58745979, ...,  0.66584016,\n",
              "         1.06582666, -3.15091598]])"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Concatenate global test sets from each file\n",
        "global_X_test = np.concatenate(global_X_)\n",
        "global_y_test = np.concatenate(global_y_)\n",
        "\n",
        "# Print the shape of concatenated global test sets\n",
        "print(\"Global test X shape:\", global_X_test.shape)\n",
        "print(\"Global test y shape:\", global_y_test.shape)\n",
        "\n",
        "global_X_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8brn81h3hfsm"
      },
      "source": [
        "**Partitioning for the various local clients (Train, Test & Validation)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wl00-wx61JFw",
        "outputId": "c8c546aa-cd49-4e5e-d0e7-a65920358c55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Global test X shape: (78809, 33)\n",
            "Global test y shape: (78809,)\n"
          ]
        }
      ],
      "source": [
        "# Function to split the global training sets into train, validation, and test sets individually\n",
        "def split_individual_train_sets(global_X_train, global_y_train, train_split=0.99):\n",
        "    X_trains_split, y_trains_split = {}, {}\n",
        "    X_vals_split, y_vals_split = {}, {}\n",
        "\n",
        "    for idx, (X, y) in enumerate(zip(global_X_train,  global_y_train)):\n",
        "        num_data = X.shape[0]\n",
        "        train_end_idx = int(train_split * num_data)\n",
        "\n",
        "        X_trains_split[str(idx)] = X[:train_end_idx]\n",
        "        y_trains_split[str(idx)] = y[:train_end_idx]\n",
        "\n",
        "        X_vals_split[str(idx)] = X[train_end_idx:]\n",
        "        y_vals_split[str(idx)] = y[train_end_idx:]\n",
        "\n",
        "    return X_trains_split, y_trains_split, X_vals_split, y_vals_split\n",
        "\n",
        "\n",
        "# Print shapes of the combined datasets\n",
        "print(f\"Global test X shape: {global_X_test.shape}\")\n",
        "print(f\"Global test y shape: {global_y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2z-TZVxNRJt"
      },
      "outputs": [],
      "source": [
        "def get_model():\n",
        "  model = Sequential()\n",
        "  model.add(tf.keras.layers.Input(shape=(33,)),)\n",
        "  model.add(Dense(4, activation='relu'),)\n",
        "  model.add(Dense(4, activation='relu'),)\n",
        "  model.add(Dense(1, activation='sigmoid'),)\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27u_YU4lXw77"
      },
      "outputs": [],
      "source": [
        "VERBOSE = 0\n",
        "NUM_CLIENTS = 3\n",
        "class FlowerClient(fl.client.NumPyClient):\n",
        "    def __init__(self, model, X_train, y_train, X_val, y_val,):\n",
        "        self.model = get_model()\n",
        "        # self.model.build(self, input_shape=(None, 43))\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_val = X_val\n",
        "        self.y_val = y_val\n",
        "\n",
        "    def get_parameters(self, config):\n",
        "        return self.model.get_weights()\n",
        "\n",
        "    def fit(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        self.model.fit(self.X_train, self.y_train, epochs=5, batch_size=128, verbose=VERBOSE)\n",
        "        return self.model.get_weights(), len(self.X_train), {}\n",
        "\n",
        "    def evaluate(self, parameters, config):\n",
        "        self.model.set_weights(parameters)\n",
        "        loss, accuracy = self.model.evaluate(self.X_val, self.y_val)\n",
        "        # Generate predictions\n",
        "        # y_pred = self.model.predict(self.X_test,verbose=VERBOSE)\n",
        "        # y_pred = (y_pred > 0.5)\n",
        "\n",
        "        # Compute classification report\n",
        "        # class_report = classification_report(self.y_test, y_pred, digits=5, zero_division=0)\n",
        "\n",
        "        return loss, len(self.X_val), {\"loss\": loss, \"accuracy\": accuracy}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsutgpfGYM6V"
      },
      "outputs": [],
      "source": [
        "## Defining the client function\n",
        "def create_client(cid, X_trains, y_trains, X_vals, y_vals) -> fl.client.Client:\n",
        "    \"\"\"Create a Flower client representing a single organization.\"\"\"\n",
        "    model = get_model()  # Pass model_class as an argument\n",
        "\n",
        "    return FlowerClient(model, X_trains[cid], y_trains[cid], X_vals[cid], y_vals[cid]).to_client()\n",
        "\n",
        "X_trains_split, y_trains_split, X_vals_split, y_vals_split = split_individual_train_sets(global_X_train, global_y_train)\n",
        "\n",
        "client_fnc = partial(\n",
        "    create_client,\n",
        "    # model_class=ANN,\n",
        "    X_trains=X_trains_split,\n",
        "    y_trains=y_trains_split,\n",
        "    X_vals=X_vals_split,\n",
        "    y_vals=y_vals_split,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F9FdO1KydFwE"
      },
      "outputs": [],
      "source": [
        "def weighted_average(metrics):\n",
        "    total_samples = sum(num_samples for num_samples, _ in metrics)\n",
        "    agg_loss = sum(num_samples * m.get(\"loss\",0) for num_samples, m in metrics) / total_samples\n",
        "    agg_accuracy = sum(num_samples * m.get(\"accuracy\",1) for num_samples, m in metrics) / total_samples\n",
        "\n",
        "    # Collect classification reports\n",
        "    # classification_reports = [m.get(\"classification_report\", \"\") for _, m in metrics]\n",
        "\n",
        "    # Print each classification report with client number\n",
        "    # for i, report in enumerate(classification_reports):\n",
        "    #     print(f\"Classification report for client {i+1}:\\n{report}\\n\")\n",
        "\n",
        "    return {\"agg_loss\": agg_loss, \"agg_accuracy\": agg_accuracy}\n",
        "\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "def get_evaluate_fn(X_test, y_test):\n",
        "    \"\"\"Return an evaluation function for server-side (i.e. centralised) evaluation.\"\"\"\n",
        "\n",
        "    # The `evaluate` function will be called after every round by the strategy\n",
        "    def evaluate(\n",
        "        server_round: int,\n",
        "        parameters: fl.common.NDArrays,\n",
        "        config: Dict[str, fl.common.Scalar],\n",
        "    ):\n",
        "        model = get_model()  # Construct the model\n",
        "        # model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "        model.set_weights(parameters)  # Update model with the latest parameters\n",
        "        loss, accuracy = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
        "        y_pred = model.predict(X_test)\n",
        "        y_pred = (y_pred > 0.5)\n",
        "        class_report = classification_report(y_test, y_pred, digits=5, zero_division=0)\n",
        "\n",
        "        return loss, {\"loss\":loss, \"accuracy\": accuracy, \"Centralised report\": class_report}\n",
        "\n",
        "    return evaluate\n",
        "\n",
        "# Create FedAvg strategy\n",
        "strategy = fl.server.strategy.FedAvg(\n",
        "    fraction_fit=1.0,  # Sample 100% of available clients for training\n",
        "    fraction_evaluate=1.0,  # Sample 100% of available clients for evaluation\n",
        "    min_fit_clients=NUM_CLIENTS,  # Never sample less than the number of clients for training\n",
        "    min_evaluate_clients=NUM_CLIENTS,  # Never sample less than the number of clients for evaluation\n",
        "    min_available_clients=NUM_CLIENTS,  # Wait until all the number of clients are available\n",
        "    evaluate_metrics_aggregation_fn=weighted_average, # aggregates federated metrics\n",
        "    evaluate_fn=get_evaluate_fn(global_X_test,global_y_test),## global evaluation function\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRHpwa7-dxND",
        "outputId": "b98cf599-7fe5-43b4-aaaa-598766d7b2e6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      Starting Flower simulation, config: num_rounds=40, no round_timeout\n",
            "INFO:flwr:Starting Flower simulation, config: num_rounds=40, no round_timeout\n",
            "/usr/lib/python3.10/subprocess.py:1796: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = _posixsubprocess.fork_exec(\n",
            "2024-06-07 18:03:22,302\tINFO worker.py:1621 -- Started a local Ray instance.\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Ray initialized with resources: {'memory': 7692015207.0, 'object_store_memory': 3846007603.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'CPU': 1.0}\n",
            "INFO:flwr:Flower VCE: Ray initialized with resources: {'memory': 7692015207.0, 'object_store_memory': 3846007603.0, 'node:__internal_head__': 1.0, 'node:172.28.0.12': 1.0, 'CPU': 1.0}\n",
            "\u001b[92mINFO \u001b[0m:      Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "INFO:flwr:Optimize your simulation with Flower VCE: https://flower.ai/docs/framework/how-to-run-simulations.html\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0}\n",
            "INFO:flwr:Flower VCE: Resources for each Virtual Client: {'num_cpus': 1, 'num_gpus': 0}\n",
            "\u001b[92mINFO \u001b[0m:      Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "INFO:flwr:Flower VCE: Creating VirtualClientEngineActorPool with 1 actors\n",
            "\u001b[92mINFO \u001b[0m:      [INIT]\n",
            "INFO:flwr:[INIT]\n",
            "\u001b[92mINFO \u001b[0m:      Requesting initial parameters from one random client\n",
            "INFO:flwr:Requesting initial parameters from one random client\n",
            "\u001b[2m\u001b[36m(pid=33088)\u001b[0m 2024-06-07 18:03:26.486162: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=33088)\u001b[0m 2024-06-07 18:03:26.486245: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=33088)\u001b[0m 2024-06-07 18:03:26.489068: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "\u001b[2m\u001b[36m(pid=33088)\u001b[0m 2024-06-07 18:03:28.406137: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[92mINFO \u001b[0m:      Received initial parameters from one random client\n",
            "INFO:flwr:Received initial parameters from one random client\n",
            "\u001b[92mINFO \u001b[0m:      Evaluating initial global parameters\n",
            "INFO:flwr:Evaluating initial global parameters\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 3s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      initial parameters (loss, other metrics): 0.5633272528648376, {'loss': 0.5633272528648376, 'accuracy': 0.9144006371498108, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.94815   0.07082   0.13179      7230\\n           1    0.91417   0.99961   0.95498     71579\\n\\n    accuracy                        0.91440     78809\\n   macro avg    0.93116   0.53521   0.54338     78809\\nweighted avg    0.91729   0.91440   0.87946     78809\\n'}\n",
            "INFO:flwr:initial parameters (loss, other metrics): 0.5633272528648376, {'loss': 0.5633272528648376, 'accuracy': 0.9144006371498108, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.94815   0.07082   0.13179      7230\\n           1    0.91417   0.99961   0.95498     71579\\n\\n    accuracy                        0.91440     78809\\n   macro avg    0.93116   0.53521   0.54338     78809\\nweighted avg    0.91729   0.91440   0.87946     78809\\n'}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 1]\n",
            "INFO:flwr:[ROUND 1]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n",
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n",
            "\u001b[93mWARNING \u001b[0m:   No fit_metrics_aggregation_fn provided\n",
            "WARNING:flwr:No fit_metrics_aggregation_fn provided\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 3s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (1, 0.593224823474884, {'loss': 0.593224823474884, 'accuracy': 0.8792269825935364, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.38736   0.54412   0.45255      7230\\n           1    0.95199   0.91308   0.93213     71579\\n\\n    accuracy                        0.87923     78809\\n   macro avg    0.66967   0.72860   0.69234     78809\\nweighted avg    0.90019   0.87923   0.88813     78809\\n'}, 79.80394400500063)\n",
            "INFO:flwr:fit progress: (1, 0.593224823474884, {'loss': 0.593224823474884, 'accuracy': 0.8792269825935364, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.38736   0.54412   0.45255      7230\\n           1    0.95199   0.91308   0.93213     71579\\n\\n    accuracy                        0.87923     78809\\n   macro avg    0.66967   0.72860   0.69234     78809\\nweighted avg    0.90019   0.87923   0.88813     78809\\n'}, 79.80394400500063)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 5.9376 - accuracy: 0.2686\n",
            " 39/126 [========>.....................] - ETA: 0s - loss: 0.7203 - accuracy: 0.7861 \n",
            "126/126 [==============================] - 0s 1ms/step - loss: 0.7486 - accuracy: 0.7779\n",
            "  1/147 [..............................] - ETA: 28s - loss: 0.4601 - accuracy: 0.8750\n",
            " 79/147 [===============>..............] - ETA: 0s - loss: 0.4236 - accuracy: 0.8805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 2]\n",
            "INFO:flwr:[ROUND 2]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/147 [======================>.......] - ETA: 0s - loss: 0.4452 - accuracy: 0.8745\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - 0s 1ms/step - loss: 0.4494 - accuracy: 0.8728\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 3s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (2, 0.8698111176490784, {'loss': 0.8698111176490784, 'accuracy': 0.8697737455368042, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.33489   0.42545   0.37478      7230\\n           1    0.94034   0.91465   0.92732     71579\\n\\n    accuracy                        0.86977     78809\\n   macro avg    0.63762   0.67005   0.65105     78809\\nweighted avg    0.88479   0.86977   0.87663     78809\\n'}, 160.71613562600032)\n",
            "INFO:flwr:fit progress: (2, 0.8698111176490784, {'loss': 0.8698111176490784, 'accuracy': 0.8697737455368042, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.33489   0.42545   0.37478      7230\\n           1    0.94034   0.91465   0.92732     71579\\n\\n    accuracy                        0.86977     78809\\n   macro avg    0.63762   0.67005   0.65105     78809\\nweighted avg    0.88479   0.86977   0.87663     78809\\n'}, 160.71613562600032)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/147 [..............................] - ETA: 30s - loss: 0.4885 - accuracy: 0.8750\n",
            " 67/147 [============>.................] - ETA: 0s - loss: 0.5422 - accuracy: 0.8741\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.5482 - accuracy: 0.8715\n",
            " 38/126 [========>.....................] - ETA: 0s - loss: 1.6305 - accuracy: 0.6258 \n",
            "126/126 [==============================] - 0s 1ms/step - loss: 1.6741 - accuracy: 0.6350\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 3]\n",
            "INFO:flwr:[ROUND 3]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 1s - loss: 12.0735 - accuracy: 0.1562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 2ms/step - loss: 10.6787 - accuracy: 0.1748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 3s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (3, 0.9248741269111633, {'loss': 0.9248741269111633, 'accuracy': 0.8882741928100586, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.42533   0.62047   0.50470      7230\\n           1    0.95980   0.91532   0.93704     71579\\n\\n    accuracy                        0.88827     78809\\n   macro avg    0.69257   0.76790   0.72087     78809\\nweighted avg    0.91077   0.88827   0.89737     78809\\n'}, 250.50570605600024)\n",
            "INFO:flwr:fit progress: (3, 0.9248741269111633, {'loss': 0.9248741269111633, 'accuracy': 0.8882741928100586, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.42533   0.62047   0.50470      7230\\n           1    0.95980   0.91532   0.93704     71579\\n\\n    accuracy                        0.88827     78809\\n   macro avg    0.69257   0.76790   0.72087     78809\\nweighted avg    0.91077   0.88827   0.89737     78809\\n'}, 250.50570605600024)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 3ms/step - loss: 14.3522 - accuracy: 0.2395\n",
            " 26/147 [====>.........................] - ETA: 0s - loss: 0.4415 - accuracy: 0.8846 \n",
            " 71/147 [=============>................] - ETA: 0s - loss: 0.4467 - accuracy: 0.8825\n",
            "120/147 [=======================>......] - ETA: 0s - loss: 0.4580 - accuracy: 0.8799\n",
            "142/147 [===========================>..] - ETA: 0s - loss: 0.4605 - accuracy: 0.8794\n",
            "147/147 [==============================] - 1s 3ms/step - loss: 0.4592 - accuracy: 0.8798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 4]\n",
            "INFO:flwr:[ROUND 4]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/126 [..............................] - ETA: 25s - loss: 0.0092 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 38/126 [========>.....................] - ETA: 0s - loss: 0.2081 - accuracy: 0.9729 \n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 75/126 [================>.............] - ETA: 0s - loss: 0.2136 - accuracy: 0.9696\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r116/126 [==========================>...] - ETA: 0s - loss: 0.2414 - accuracy: 0.9685\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 0s 1ms/step - loss: 0.2459 - accuracy: 0.9676\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 3s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (4, 1.1406844854354858, {'loss': 1.1406844854354858, 'accuracy': 0.88299560546875, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40123   0.55934   0.46727      7230\\n           1    0.95364   0.91569   0.93428     71579\\n\\n    accuracy                        0.88300     78809\\n   macro avg    0.67744   0.73751   0.70078     78809\\nweighted avg    0.90297   0.88300   0.89144     78809\\n'}, 331.84245423300035)\n",
            "INFO:flwr:fit progress: (4, 1.1406844854354858, {'loss': 1.1406844854354858, 'accuracy': 0.88299560546875, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40123   0.55934   0.46727      7230\\n           1    0.95364   0.91569   0.93428     71579\\n\\n    accuracy                        0.88300     78809\\n   macro avg    0.67744   0.73751   0.70078     78809\\nweighted avg    0.90297   0.88300   0.89144     78809\\n'}, 331.84245423300035)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/147 [..............................] - ETA: 48s - loss: 0.3651 - accuracy: 0.8750\n",
            " 54/147 [==========>...................] - ETA: 0s - loss: 0.3534 - accuracy: 0.8854\n",
            "103/147 [====================>.........] - ETA: 0s - loss: 0.3572 - accuracy: 0.8835\n",
            "147/147 [==============================] - 1s 2ms/step - loss: 0.3719 - accuracy: 0.8800\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 20.7224 - accuracy: 0.0971\n",
            "  1/126 [..............................] - ETA: 41s - loss: 8.2800e-04 - accuracy: 1.0000\n",
            " 47/126 [==========>...................] - ETA: 0s - loss: 0.1852 - accuracy: 0.9834\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 5]\n",
            "INFO:flwr:[ROUND 5]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 69/126 [===============>..............] - ETA: 0s - loss: 0.2102 - accuracy: 0.9814\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 95/126 [=====================>........] - ETA: 0s - loss: 0.2158 - accuracy: 0.9809\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r114/126 [==========================>...] - ETA: 0s - loss: 0.2272 - accuracy: 0.9800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 1s 2ms/step - loss: 0.2310 - accuracy: 0.9795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (5, 1.1973904371261597, {'loss': 1.1973904371261597, 'accuracy': 0.8832747340202332, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40182   0.55726   0.46694      7230\\n           1    0.95346   0.91620   0.93446     71579\\n\\n    accuracy                        0.88327     78809\\n   macro avg    0.67764   0.73673   0.70070     78809\\nweighted avg    0.90285   0.88327   0.89157     78809\\n'}, 419.37203838799996)\n",
            "INFO:flwr:fit progress: (5, 1.1973904371261597, {'loss': 1.1973904371261597, 'accuracy': 0.8832747340202332, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40182   0.55726   0.46694      7230\\n           1    0.95346   0.91620   0.93446     71579\\n\\n    accuracy                        0.88327     78809\\n   macro avg    0.67764   0.73673   0.70070     78809\\nweighted avg    0.90285   0.88327   0.89157     78809\\n'}, 419.37203838799996)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 3ms/step - loss: 23.4283 - accuracy: 0.0744\n",
            "  1/147 [..............................] - ETA: 36s - loss: 0.2762 - accuracy: 0.8750\n",
            " 67/147 [============>.................] - ETA: 0s - loss: 0.2578 - accuracy: 0.8829\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.2681 - accuracy: 0.8807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 6]\n",
            "INFO:flwr:[ROUND 6]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/126 [..............................] - ETA: 25s - loss: 0.0013 - accuracy: 1.0000\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 39/126 [========>.....................] - ETA: 0s - loss: 0.2569 - accuracy: 0.9832 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 78/126 [=================>............] - ETA: 0s - loss: 0.2531 - accuracy: 0.9828\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 0s 1ms/step - loss: 0.2916 - accuracy: 0.9803\n",
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (6, 1.2157864570617676, {'loss': 1.2157864570617676, 'accuracy': 0.8825514912605286, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.39829   0.54869   0.46155      7230\\n           1    0.95261   0.91627   0.93409     71579\\n\\n    accuracy                        0.88255     78809\\n   macro avg    0.67545   0.73248   0.69782     78809\\nweighted avg    0.90175   0.88255   0.89074     78809\\n'}, 503.4430657510002)\n",
            "INFO:flwr:fit progress: (6, 1.2157864570617676, {'loss': 1.2157864570617676, 'accuracy': 0.8825514912605286, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.39829   0.54869   0.46155      7230\\n           1    0.95261   0.91627   0.93409     71579\\n\\n    accuracy                        0.88255     78809\\n   macro avg    0.67545   0.73248   0.69782     78809\\nweighted avg    0.90175   0.88255   0.89074     78809\\n'}, 503.4430657510002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 3ms/step - loss: 25.0055 - accuracy: 0.0680\n",
            " 25/147 [====>.........................] - ETA: 0s - loss: 0.1682 - accuracy: 0.8838 \n",
            " 69/147 [=============>................] - ETA: 0s - loss: 0.1704 - accuracy: 0.8832\n",
            "107/147 [====================>.........] - ETA: 0s - loss: 0.1697 - accuracy: 0.8841\n",
            "147/147 [==============================] - 1s 3ms/step - loss: 0.1772 - accuracy: 0.8807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 7]\n",
            "INFO:flwr:[ROUND 7]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/126 [..............................] - ETA: 26s - loss: 5.1629e-04 - accuracy: 1.0000\n",
            " 38/126 [========>.....................] - ETA: 0s - loss: 0.4236 - accuracy: 0.9836     \n",
            "113/126 [=========================>....] - ETA: 0s - loss: 0.4774 - accuracy: 0.9806\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 0.4836 - accuracy: 0.9805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 6s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (7, 1.2410391569137573, {'loss': 1.2410391569137573, 'accuracy': 0.8831605315208435, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40173   0.55920   0.46756      7230\\n           1    0.95364   0.91588   0.93438     71579\\n\\n    accuracy                        0.88316     78809\\n   macro avg    0.67768   0.73754   0.70097     78809\\nweighted avg    0.90301   0.88316   0.89155     78809\\n'}, 595.0749961390002)\n",
            "INFO:flwr:fit progress: (7, 1.2410391569137573, {'loss': 1.2410391569137573, 'accuracy': 0.8831605315208435, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40173   0.55920   0.46756      7230\\n           1    0.95364   0.91588   0.93438     71579\\n\\n    accuracy                        0.88316     78809\\n   macro avg    0.67768   0.73754   0.70097     78809\\nweighted avg    0.90301   0.88316   0.89155     78809\\n'}, 595.0749961390002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/147 [..............................] - ETA: 37s - loss: 0.2002 - accuracy: 0.8750\n",
            " 71/147 [=============>................] - ETA: 0s - loss: 0.1915 - accuracy: 0.8825\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.1977 - accuracy: 0.8802\n",
            "  1/126 [..............................] - ETA: 27s - loss: 0.0038 - accuracy: 1.0000\n",
            " 65/126 [==============>...............] - ETA: 0s - loss: 0.4471 - accuracy: 0.9841\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.9805\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 8]\n",
            "INFO:flwr:[ROUND 8]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 1s - loss: 24.6055 - accuracy: 0.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 2ms/step - loss: 25.0947 - accuracy: 0.0841\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (8, 1.2876172065734863, {'loss': 1.2876172065734863, 'accuracy': 0.8847847580909729, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40930   0.57732   0.47900      7230\\n           1    0.95546   0.91584   0.93523     71579\\n\\n    accuracy                        0.88478     78809\\n   macro avg    0.68238   0.74658   0.70712     78809\\nweighted avg    0.90535   0.88478   0.89338     78809\\n'}, 678.880048039)\n",
            "INFO:flwr:fit progress: (8, 1.2876172065734863, {'loss': 1.2876172065734863, 'accuracy': 0.8847847580909729, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40930   0.57732   0.47900      7230\\n           1    0.95546   0.91584   0.93523     71579\\n\\n    accuracy                        0.88478     78809\\n   macro avg    0.68238   0.74658   0.70712     78809\\nweighted avg    0.90535   0.88478   0.89338     78809\\n'}, 678.880048039)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 25.7785 - accuracy: 0.1133\n",
            " 37/147 [======>.......................] - ETA: 0s - loss: 0.2054 - accuracy: 0.8877 \n",
            "114/147 [======================>.......] - ETA: 0s - loss: 0.2210 - accuracy: 0.8808\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 9]\n",
            "INFO:flwr:[ROUND 9]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147/147 [==============================] - 0s 1ms/step - loss: 0.2226 - accuracy: 0.8802\n",
            "  1/126 [..............................] - ETA: 27s - loss: 0.0016 - accuracy: 1.0000\n",
            " 73/126 [================>.............] - ETA: 0s - loss: 0.5404 - accuracy: 0.9824\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 0.6120 - accuracy: 0.9803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (9, 1.3448415994644165, {'loss': 1.3448415994644165, 'accuracy': 0.8877792954444885, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.41932   0.58008   0.48677      7230\\n           1    0.95588   0.91886   0.93700     71579\\n\\n    accuracy                        0.88778     78809\\n   macro avg    0.68760   0.74947   0.71189     78809\\nweighted avg    0.90665   0.88778   0.89570     78809\\n'}, 763.8648836770008)\n",
            "INFO:flwr:fit progress: (9, 1.3448415994644165, {'loss': 1.3448415994644165, 'accuracy': 0.8877792954444885, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.41932   0.58008   0.48677      7230\\n           1    0.95588   0.91886   0.93700     71579\\n\\n    accuracy                        0.88778     78809\\n   macro avg    0.68760   0.74947   0.71189     78809\\nweighted avg    0.90665   0.88778   0.89570     78809\\n'}, 763.8648836770008)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/126 [..............................] - ETA: 26s - loss: 0.0275 - accuracy: 0.9688\n",
            " 65/126 [==============>...............] - ETA: 0s - loss: 0.5600 - accuracy: 0.9837\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 0.7035 - accuracy: 0.9800\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 27.4957 - accuracy: 0.1294\n",
            "  1/147 [..............................] - ETA: 32s - loss: 0.1945 - accuracy: 0.8750\n",
            " 63/147 [===========>..................] - ETA: 0s - loss: 0.1802 - accuracy: 0.8859\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 10]\n",
            "INFO:flwr:[ROUND 10]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 82/147 [===============>..............] - ETA: 0s - loss: 0.1725 - accuracy: 0.8899\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r106/147 [====================>.........] - ETA: 0s - loss: 0.1754 - accuracy: 0.8880\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r124/147 [========================>.....] - ETA: 0s - loss: 0.1817 - accuracy: 0.8851\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - ETA: 0s - loss: 0.1816 - accuracy: 0.8849\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - 1s 2ms/step - loss: 0.1816 - accuracy: 0.8849\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (10, 1.377259373664856, {'loss': 1.377259373664856, 'accuracy': 0.8845182657241821, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40784   0.57261   0.47638      7230\\n           1    0.95499   0.91602   0.93510     71579\\n\\n    accuracy                        0.88452     78809\\n   macro avg    0.68142   0.74432   0.70574     78809\\nweighted avg    0.90480   0.88452   0.89302     78809\\n'}, 854.0028185300007)\n",
            "INFO:flwr:fit progress: (10, 1.377259373664856, {'loss': 1.377259373664856, 'accuracy': 0.8845182657241821, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.40784   0.57261   0.47638      7230\\n           1    0.95499   0.91602   0.93510     71579\\n\\n    accuracy                        0.88452     78809\\n   macro avg    0.68142   0.74432   0.70574     78809\\nweighted avg    0.90480   0.88452   0.89302     78809\\n'}, 854.0028185300007)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 28.3194 - accuracy: 0.1100\n",
            " 24/147 [===>..........................] - ETA: 0s - loss: 0.1559 - accuracy: 0.8893 \n",
            " 71/147 [=============>................] - ETA: 0s - loss: 0.1657 - accuracy: 0.8825\n",
            "118/147 [=======================>......] - ETA: 0s - loss: 0.1685 - accuracy: 0.8816\n",
            "141/147 [===========================>..] - ETA: 0s - loss: 0.1700 - accuracy: 0.8812\n",
            "147/147 [==============================] - 1s 2ms/step - loss: 0.1704 - accuracy: 0.8809\n",
            " 24/126 [====>.........................] - ETA: 0s - loss: 0.6510 - accuracy: 0.9831 \n",
            " 73/126 [================>.............] - ETA: 0s - loss: 0.6688 - accuracy: 0.9824\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 11]\n",
            "INFO:flwr:[ROUND 11]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 97/126 [======================>.......] - ETA: 0s - loss: 0.7060 - accuracy: 0.9816\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r121/126 [===========================>..] - ETA: 0s - loss: 0.7333 - accuracy: 0.9811\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 1s 2ms/step - loss: 0.7557 - accuracy: 0.9803\n",
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (11, 1.3616935014724731, {'loss': 1.3616935014724731, 'accuracy': 0.885469913482666, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.41230   0.58396   0.48334      7230\\n           1    0.95613   0.91593   0.93560     71579\\n\\n    accuracy                        0.88547     78809\\n   macro avg    0.68422   0.74994   0.70947     78809\\nweighted avg    0.90624   0.88547   0.89411     78809\\n'}, 937.0436825430006)\n",
            "INFO:flwr:fit progress: (11, 1.3616935014724731, {'loss': 1.3616935014724731, 'accuracy': 0.885469913482666, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.41230   0.58396   0.48334      7230\\n           1    0.95613   0.91593   0.93560     71579\\n\\n    accuracy                        0.88547     78809\\n   macro avg    0.68422   0.74994   0.70947     78809\\nweighted avg    0.90624   0.88547   0.89411     78809\\n'}, 937.0436825430006)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/126 [..............................] - ETA: 38s - loss: 0.0061 - accuracy: 1.0000\n",
            " 50/126 [==========>...................] - ETA: 0s - loss: 0.6520 - accuracy: 0.9837\n",
            "100/126 [======================>.......] - ETA: 0s - loss: 0.7979 - accuracy: 0.9806\n",
            "126/126 [==============================] - 1s 2ms/step - loss: 0.8335 - accuracy: 0.9798\n",
            "  1/147 [..............................] - ETA: 47s - loss: 0.1753 - accuracy: 0.8750\n",
            " 49/147 [=========>....................] - ETA: 0s - loss: 0.1509 - accuracy: 0.8890\n",
            " 97/147 [==================>...........] - ETA: 0s - loss: 0.1595 - accuracy: 0.8831\n",
            "119/147 [=======================>......] - ETA: 0s - loss: 0.1640 - accuracy: 0.8813\n",
            "147/147 [==============================] - 1s 2ms/step - loss: 0.1654 - accuracy: 0.8807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 12]\n",
            "INFO:flwr:[ROUND 12]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 3s - loss: 27.0198 - accuracy: 0.1875\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 3ms/step - loss: 27.9238 - accuracy: 0.1359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (12, 1.5094852447509766, {'loss': 1.5094852447509766, 'accuracy': 0.8889467120170593, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.42137   0.56404   0.48238      7230\\n           1    0.95441   0.92176   0.93780     71579\\n\\n    accuracy                        0.88895     78809\\n   macro avg    0.68789   0.74290   0.71009     78809\\nweighted avg    0.90550   0.88895   0.89602     78809\\n'}, 1028.7599831900006)\n",
            "INFO:flwr:fit progress: (12, 1.5094852447509766, {'loss': 1.5094852447509766, 'accuracy': 0.8889467120170593, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.42137   0.56404   0.48238      7230\\n           1    0.95441   0.92176   0.93780     71579\\n\\n    accuracy                        0.88895     78809\\n   macro avg    0.68789   0.74290   0.71009     78809\\nweighted avg    0.90550   0.88895   0.89602     78809\\n'}, 1028.7599831900006)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/147 [..............................] - ETA: 30s - loss: 0.1689 - accuracy: 0.8750\n",
            " 72/147 [=============>................] - ETA: 0s - loss: 0.1474 - accuracy: 0.8941\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.1535 - accuracy: 0.8916\n",
            " 1/10 [==>...........................] - ETA: 1s - loss: 29.5267 - accuracy: 0.0938\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 31.3427 - accuracy: 0.0874\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 13]\n",
            "INFO:flwr:[ROUND 13]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/126 [..............................] - ETA: 25s - loss: 0.0693 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 36/126 [=======>......................] - ETA: 0s - loss: 0.8191 - accuracy: 0.9766 \n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 72/126 [================>.............] - ETA: 0s - loss: 0.7999 - accuracy: 0.9770\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111/126 [=========================>....] - ETA: 0s - loss: 0.8839 - accuracy: 0.9755\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 0s 1ms/step - loss: 0.8828 - accuracy: 0.9758\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (13, 1.6048648357391357, {'loss': 1.6048648357391357, 'accuracy': 0.8889340162277222, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.42361   0.58409   0.49108      7230\\n           1    0.95632   0.91973   0.93767     71579\\n\\n    accuracy                        0.88893     78809\\n   macro avg    0.68997   0.75191   0.71437     78809\\nweighted avg    0.90745   0.88893   0.89669     78809\\n'}, 1113.9209665930002)\n",
            "INFO:flwr:fit progress: (13, 1.6048648357391357, {'loss': 1.6048648357391357, 'accuracy': 0.8889340162277222, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.42361   0.58409   0.49108      7230\\n           1    0.95632   0.91973   0.93767     71579\\n\\n    accuracy                        0.88893     78809\\n   macro avg    0.68997   0.75191   0.71437     78809\\nweighted avg    0.90745   0.88893   0.89669     78809\\n'}, 1113.9209665930002)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 33.7639 - accuracy: 0.1165\n",
            " 26/147 [====>.........................] - ETA: 0s - loss: 0.1222 - accuracy: 0.8918 \n",
            "101/147 [===================>..........] - ETA: 0s - loss: 0.1240 - accuracy: 0.8895\n",
            "139/147 [===========================>..] - ETA: 0s - loss: 0.1307 - accuracy: 0.8862\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 14]\n",
            "INFO:flwr:[ROUND 14]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.8869\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/126 [..............................] - ETA: 26s - loss: 0.0400 - accuracy: 0.9688\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 38/126 [========>.....................] - ETA: 0s - loss: 0.7914 - accuracy: 0.9803 \n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 72/126 [================>.............] - ETA: 0s - loss: 0.8161 - accuracy: 0.9800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r109/126 [========================>.....] - ETA: 0s - loss: 0.8895 - accuracy: 0.9788\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 0s 1ms/step - loss: 0.9058 - accuracy: 0.9785\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (14, 1.6292552947998047, {'loss': 1.6292552947998047, 'accuracy': 0.891471803188324, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.43299   0.59115   0.49985      7230\\n           1    0.95712   0.92181   0.93913     71579\\n\\n    accuracy                        0.89147     78809\\n   macro avg    0.69505   0.75648   0.71949     78809\\nweighted avg    0.90904   0.89147   0.89883     78809\\n'}, 1202.6880980000005)\n",
            "INFO:flwr:fit progress: (14, 1.6292552947998047, {'loss': 1.6292552947998047, 'accuracy': 0.891471803188324, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.43299   0.59115   0.49985      7230\\n           1    0.95712   0.92181   0.93913     71579\\n\\n    accuracy                        0.89147     78809\\n   macro avg    0.69505   0.75648   0.71949     78809\\nweighted avg    0.90904   0.89147   0.89883     78809\\n'}, 1202.6880980000005)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/126 [..............................] - ETA: 42s - loss: 0.0044 - accuracy: 1.0000\n",
            " 31/126 [======>.......................] - ETA: 0s - loss: 0.7768 - accuracy: 0.9819\n",
            " 72/126 [================>.............] - ETA: 0s - loss: 0.7809 - accuracy: 0.9818\n",
            "111/126 [=========================>....] - ETA: 0s - loss: 0.8676 - accuracy: 0.9803\n",
            "126/126 [==============================] - 1s 3ms/step - loss: 0.8676 - accuracy: 0.9803\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 34.5472 - accuracy: 0.1456\n",
            " 24/147 [===>..........................] - ETA: 0s - loss: 0.0930 - accuracy: 0.8997 \n",
            " 72/147 [=============>................] - ETA: 0s - loss: 0.1010 - accuracy: 0.8937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 15]\n",
            "INFO:flwr:[ROUND 15]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 92/147 [=================>............] - ETA: 0s - loss: 0.1015 - accuracy: 0.8940\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r115/147 [======================>.......] - ETA: 0s - loss: 0.1049 - accuracy: 0.8910\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r128/147 [=========================>....] - ETA: 0s - loss: 0.1062 - accuracy: 0.8892\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - 1s 2ms/step - loss: 0.1060 - accuracy: 0.8909\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 5s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (15, 1.6762031316757202, {'loss': 1.6762031316757202, 'accuracy': 0.9556015133857727, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.90300   0.57815   0.70495      7230\\n           1    0.95888   0.99373   0.97599     71579\\n\\n    accuracy                        0.95560     78809\\n   macro avg    0.93094   0.78594   0.84047     78809\\nweighted avg    0.95376   0.95560   0.95113     78809\\n'}, 1294.7739133320001)\n",
            "INFO:flwr:fit progress: (15, 1.6762031316757202, {'loss': 1.6762031316757202, 'accuracy': 0.9556015133857727, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.90300   0.57815   0.70495      7230\\n           1    0.95888   0.99373   0.97599     71579\\n\\n    accuracy                        0.95560     78809\\n   macro avg    0.93094   0.78594   0.84047     78809\\nweighted avg    0.95376   0.95560   0.95113     78809\\n'}, 1294.7739133320001)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 40/126 [========>.....................] - ETA: 0s - loss: 0.7809 - accuracy: 0.9820 \n",
            " 75/126 [================>.............] - ETA: 0s - loss: 0.8159 - accuracy: 0.9808\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 0.9424 - accuracy: 0.9785\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 36.4198 - accuracy: 0.1100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 16]\n",
            "INFO:flwr:[ROUND 16]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/147 [..............................] - ETA: 31s - loss: 0.0322 - accuracy: 1.0000\n",
            " 75/147 [==============>...............] - ETA: 0s - loss: 0.0382 - accuracy: 0.9908\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0432 - accuracy: 0.9889\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 3s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (16, 1.7921123504638672, {'loss': 1.7921123504638672, 'accuracy': 0.9610831141471863, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.98038   0.58755   0.73476      7230\\n           1    0.95996   0.99881   0.97900     71579\\n\\n    accuracy                        0.96108     78809\\n   macro avg    0.97017   0.79318   0.85688     78809\\nweighted avg    0.96183   0.96108   0.95659     78809\\n'}, 1380.1213361990003)\n",
            "INFO:flwr:fit progress: (16, 1.7921123504638672, {'loss': 1.7921123504638672, 'accuracy': 0.9610831141471863, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.98038   0.58755   0.73476      7230\\n           1    0.95996   0.99881   0.97900     71579\\n\\n    accuracy                        0.96108     78809\\n   macro avg    0.97017   0.79318   0.85688     78809\\nweighted avg    0.96183   0.96108   0.95659     78809\\n'}, 1380.1213361990003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 39.0728 - accuracy: 0.1392\n",
            " 39/147 [======>.......................] - ETA: 0s - loss: 0.0210 - accuracy: 0.9984 \n",
            "117/147 [======================>.......] - ETA: 0s - loss: 0.0241 - accuracy: 0.9979\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 17]\n",
            "INFO:flwr:[ROUND 17]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0248 - accuracy: 0.9972\n",
            "  1/126 [..............................] - ETA: 24s - loss: 0.0059 - accuracy: 1.0000\n",
            " 76/126 [=================>............] - ETA: 0s - loss: 0.8825 - accuracy: 0.9819\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 1.0055 - accuracy: 0.9798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 5s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (17, 1.8987363576889038, {'loss': 1.8987363576889038, 'accuracy': 0.9590402245521545, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.98615   0.56141   0.71549      7230\\n           1    0.95755   0.99920   0.97793     71579\\n\\n    accuracy                        0.95904     78809\\n   macro avg    0.97185   0.78031   0.84671     78809\\nweighted avg    0.96017   0.95904   0.95386     78809\\n'}, 1474.9770314950001)\n",
            "INFO:flwr:fit progress: (17, 1.8987363576889038, {'loss': 1.8987363576889038, 'accuracy': 0.9590402245521545, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.98615   0.56141   0.71549      7230\\n           1    0.95755   0.99920   0.97793     71579\\n\\n    accuracy                        0.95904     78809\\n   macro avg    0.97185   0.78031   0.84671     78809\\nweighted avg    0.96017   0.95904   0.95386     78809\\n'}, 1474.9770314950001)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/147 [..............................] - ETA: 29s - loss: 0.0051 - accuracy: 1.0000\n",
            " 73/147 [=============>................] - ETA: 0s - loss: 0.0110 - accuracy: 0.9991\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0147 - accuracy: 0.9985\n",
            " 40/126 [========>.....................] - ETA: 0s - loss: 0.8848 - accuracy: 0.9836 \n",
            "115/126 [==========================>...] - ETA: 0s - loss: 1.0421 - accuracy: 0.9807\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 18]\n",
            "INFO:flwr:[ROUND 18]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 0s 1ms/step - loss: 1.0692 - accuracy: 0.9800\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 1s - loss: 40.5443 - accuracy: 0.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 2ms/step - loss: 41.5765 - accuracy: 0.0712\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (18, 1.9275610446929932, {'loss': 1.9275610446929932, 'accuracy': 0.9605374932289124, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.98931   0.57607   0.72815      7230\\n           1    0.95891   0.99937   0.97872     71579\\n\\n    accuracy                        0.96054     78809\\n   macro avg    0.97411   0.78772   0.85344     78809\\nweighted avg    0.96170   0.96054   0.95574     78809\\n'}, 1562.684442144)\n",
            "INFO:flwr:fit progress: (18, 1.9275610446929932, {'loss': 1.9275610446929932, 'accuracy': 0.9605374932289124, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.98931   0.57607   0.72815      7230\\n           1    0.95891   0.99937   0.97872     71579\\n\\n    accuracy                        0.96054     78809\\n   macro avg    0.97411   0.78772   0.85344     78809\\nweighted avg    0.96170   0.96054   0.95574     78809\\n'}, 1562.684442144)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 42.2040 - accuracy: 0.1036\n",
            "  1/147 [..............................] - ETA: 45s - loss: 0.0011 - accuracy: 1.0000\n",
            " 49/147 [=========>....................] - ETA: 0s - loss: 0.0067 - accuracy: 0.9987\n",
            " 95/147 [==================>...........] - ETA: 0s - loss: 0.0064 - accuracy: 0.9993\n",
            "136/147 [==========================>...] - ETA: 0s - loss: 0.0092 - accuracy: 0.9989\n",
            "147/147 [==============================] - 1s 2ms/step - loss: 0.0091 - accuracy: 0.9989\n",
            "  1/126 [..............................] - ETA: 38s - loss: 0.0039 - accuracy: 1.0000\n",
            " 49/126 [==========>...................] - ETA: 0s - loss: 0.7593 - accuracy: 0.9847\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 19]\n",
            "INFO:flwr:[ROUND 19]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 72/126 [================>.............] - ETA: 0s - loss: 0.8986 - accuracy: 0.9813\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 98/126 [======================>.......] - ETA: 0s - loss: 0.9387 - accuracy: 0.9809\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r116/126 [==========================>...] - ETA: 0s - loss: 0.9651 - accuracy: 0.9806\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 1s 2ms/step - loss: 0.9993 - accuracy: 0.9798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (19, 1.927960753440857, {'loss': 1.927960753440857, 'accuracy': 0.9597000479698181, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99009   0.56639   0.72057      7230\\n           1    0.95802   0.99943   0.97828     71579\\n\\n    accuracy                        0.95970     78809\\n   macro avg    0.97405   0.78291   0.84943     78809\\nweighted avg    0.96096   0.95970   0.95464     78809\\n'}, 1648.2382542610003)\n",
            "INFO:flwr:fit progress: (19, 1.927960753440857, {'loss': 1.927960753440857, 'accuracy': 0.9597000479698181, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99009   0.56639   0.72057      7230\\n           1    0.95802   0.99943   0.97828     71579\\n\\n    accuracy                        0.95970     78809\\n   macro avg    0.97405   0.78291   0.84943     78809\\nweighted avg    0.96096   0.95970   0.95464     78809\\n'}, 1648.2382542610003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 3ms/step - loss: 42.2696 - accuracy: 0.0874\n",
            "  1/147 [..............................] - ETA: 45s - loss: 2.1505e-04 - accuracy: 1.0000\n",
            " 46/147 [========>.....................] - ETA: 0s - loss: 0.0036 - accuracy: 1.0000\n",
            " 89/147 [=================>............] - ETA: 0s - loss: 0.0044 - accuracy: 0.9996\n",
            "106/147 [====================>.........] - ETA: 0s - loss: 0.0040 - accuracy: 0.9997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 20]\n",
            "INFO:flwr:[ROUND 20]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147/147 [==============================] - 1s 3ms/step - loss: 0.0069 - accuracy: 0.9991\n",
            "  1/126 [..............................] - ETA: 27s - loss: 0.0100 - accuracy: 1.0000\n",
            " 71/126 [===============>..............] - ETA: 0s - loss: 0.9285 - accuracy: 0.9811\n",
            "108/126 [========================>.....] - ETA: 0s - loss: 1.0394 - accuracy: 0.9795\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 1.0490 - accuracy: 0.9793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 5s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (20, 1.8559390306472778, {'loss': 1.8559390306472778, 'accuracy': 0.9611465930938721, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99035   0.58216   0.73328      7230\\n           1    0.95948   0.99943   0.97905     71579\\n\\n    accuracy                        0.96115     78809\\n   macro avg    0.97492   0.79079   0.85616     78809\\nweighted avg    0.96231   0.96115   0.95650     78809\\n'}, 1741.650151289)\n",
            "INFO:flwr:fit progress: (20, 1.8559390306472778, {'loss': 1.8559390306472778, 'accuracy': 0.9611465930938721, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99035   0.58216   0.73328      7230\\n           1    0.95948   0.99943   0.97905     71579\\n\\n    accuracy                        0.96115     78809\\n   macro avg    0.97492   0.79079   0.85616     78809\\nweighted avg    0.96231   0.96115   0.95650     78809\\n'}, 1741.650151289)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 37/126 [=======>......................] - ETA: 0s - loss: 0.8590 - accuracy: 0.9831     \n",
            "126/126 [==============================] - 0s 1ms/step - loss: 0.9648 - accuracy: 0.9800\n",
            " 36/147 [======>.......................] - ETA: 0s - loss: 0.0048 - accuracy: 1.0000     \n",
            "106/147 [====================>.........] - ETA: 0s - loss: 0.0049 - accuracy: 0.9997\n",
            "147/147 [==============================] - 0s 2ms/step - loss: 0.0081 - accuracy: 0.9991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 21]\n",
            "INFO:flwr:[ROUND 21]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 2s - loss: 39.5391 - accuracy: 0.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 2ms/step - loss: 40.6105 - accuracy: 0.1133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (21, 1.9612752199172974, {'loss': 1.9612752199172974, 'accuracy': 0.9618317484855652, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99207   0.58866   0.73889      7230\\n           1    0.96009   0.99953   0.97941     71579\\n\\n    accuracy                        0.96183     78809\\n   macro avg    0.97608   0.79409   0.85915     78809\\nweighted avg    0.96302   0.96183   0.95735     78809\\n'}, 1830.044170219)\n",
            "INFO:flwr:fit progress: (21, 1.9612752199172974, {'loss': 1.9612752199172974, 'accuracy': 0.9618317484855652, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99207   0.58866   0.73889      7230\\n           1    0.96009   0.99953   0.97941     71579\\n\\n    accuracy                        0.96183     78809\\n   macro avg    0.97608   0.79409   0.85915     78809\\nweighted avg    0.96302   0.96183   0.95735     78809\\n'}, 1830.044170219)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 35/147 [======>.......................] - ETA: 0s - loss: 0.0022 - accuracy: 1.0000     \n",
            " 77/147 [==============>...............] - ETA: 0s - loss: 0.0026 - accuracy: 0.9996\n",
            "116/147 [======================>.......] - ETA: 0s - loss: 0.0053 - accuracy: 0.9992\n",
            "147/147 [==============================] - 1s 2ms/step - loss: 0.0060 - accuracy: 0.9989\n",
            "  1/126 [..............................] - ETA: 37s - loss: 0.0014 - accuracy: 1.0000\n",
            " 50/126 [==========>...................] - ETA: 0s - loss: 0.8157 - accuracy: 0.9844\n",
            " 99/126 [======================>.......] - ETA: 0s - loss: 0.9891 - accuracy: 0.9804\n",
            "126/126 [==============================] - 1s 2ms/step - loss: 1.0430 - accuracy: 0.9795\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 22]\n",
            "INFO:flwr:[ROUND 22]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 2s - loss: 42.1186 - accuracy: 0.1562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 4ms/step - loss: 42.8219 - accuracy: 0.1262\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (22, 1.9139714241027832, {'loss': 1.9139714241027832, 'accuracy': 0.960994303226471, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99288   0.57898   0.73143      7230\\n           1    0.95919   0.99958   0.97897     71579\\n\\n    accuracy                        0.96099     78809\\n   macro avg    0.97604   0.78928   0.85520     78809\\nweighted avg    0.96228   0.96099   0.95626     78809\\n'}, 1915.9919919740005)\n",
            "INFO:flwr:fit progress: (22, 1.9139714241027832, {'loss': 1.9139714241027832, 'accuracy': 0.960994303226471, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99288   0.57898   0.73143      7230\\n           1    0.95919   0.99958   0.97897     71579\\n\\n    accuracy                        0.96099     78809\\n   macro avg    0.97604   0.78928   0.85520     78809\\nweighted avg    0.96228   0.96099   0.95626     78809\\n'}, 1915.9919919740005)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/147 [..............................] - ETA: 44s - loss: 5.7673e-05 - accuracy: 1.0000\n",
            " 49/147 [=========>....................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            " 97/147 [==================>...........] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "136/147 [==========================>...] - ETA: 0s - loss: 0.0046 - accuracy: 0.9995\n",
            "147/147 [==============================] - 1s 2ms/step - loss: 0.0044 - accuracy: 0.9996\n",
            " 24/126 [====>.........................] - ETA: 0s - loss: 0.9440 - accuracy: 0.9805 \n",
            " 71/126 [===============>..............] - ETA: 0s - loss: 0.9663 - accuracy: 0.9811\n",
            "116/126 [==========================>...] - ETA: 0s - loss: 1.0532 - accuracy: 0.9801\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 23]\n",
            "INFO:flwr:[ROUND 23]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 1s 2ms/step - loss: 1.0927 - accuracy: 0.9793\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 1s - loss: 40.9325 - accuracy: 0.1562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 2ms/step - loss: 41.7390 - accuracy: 0.1068\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 5s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (23, 2.0630550384521484, {'loss': 2.0630550384521484, 'accuracy': 0.9589514136314392, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99236   0.55685   0.71339      7230\\n           1    0.95714   0.99957   0.97789     71579\\n\\n    accuracy                        0.95895     78809\\n   macro avg    0.97475   0.77821   0.84564     78809\\nweighted avg    0.96037   0.95895   0.95363     78809\\n'}, 2006.906376498)\n",
            "INFO:flwr:fit progress: (23, 2.0630550384521484, {'loss': 2.0630550384521484, 'accuracy': 0.9589514136314392, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99236   0.55685   0.71339      7230\\n           1    0.95714   0.99957   0.97789     71579\\n\\n    accuracy                        0.95895     78809\\n   macro avg    0.97475   0.77821   0.84564     78809\\nweighted avg    0.96037   0.95895   0.95363     78809\\n'}, 2006.906376498)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 38/126 [========>.....................] - ETA: 0s - loss: 0.9727 - accuracy: 0.9811 \n",
            "126/126 [==============================] - 0s 1ms/step - loss: 1.1200 - accuracy: 0.9785\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 45.1744 - accuracy: 0.0615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 24]\n",
            "INFO:flwr:[ROUND 24]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/147 [..............................] - ETA: 30s - loss: 6.5737e-05 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 38/147 [======>.......................] - ETA: 0s - loss: 0.0017 - accuracy: 1.0000     \n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 72/147 [=============>................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r110/147 [=====================>........] - ETA: 0s - loss: 0.0037 - accuracy: 0.9997\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - ETA: 0s - loss: 0.0046 - accuracy: 0.9996\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (24, 2.05899715423584, {'loss': 2.05899715423584, 'accuracy': 0.9587610363960266, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.98822   0.55712   0.71254      7230\\n           1    0.95715   0.99933   0.97779     71579\\n\\n    accuracy                        0.95876     78809\\n   macro avg    0.97269   0.77823   0.84516     78809\\nweighted avg    0.96000   0.95876   0.95345     78809\\n'}, 2091.9235085220007)\n",
            "INFO:flwr:fit progress: (24, 2.05899715423584, {'loss': 2.05899715423584, 'accuracy': 0.9587610363960266, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.98822   0.55712   0.71254      7230\\n           1    0.95715   0.99933   0.97779     71579\\n\\n    accuracy                        0.95876     78809\\n   macro avg    0.97269   0.77823   0.84516     78809\\nweighted avg    0.96000   0.95876   0.95345     78809\\n'}, 2091.9235085220007)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/126 [..............................] - ETA: 25s - loss: 2.6556e-04 - accuracy: 1.0000\n",
            " 75/126 [================>.............] - ETA: 0s - loss: 0.8214 - accuracy: 0.9821\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 0.9565 - accuracy: 0.9795\n",
            "  1/147 [..............................] - ETA: 38s - loss: 5.4794e-05 - accuracy: 1.0000\n",
            " 69/147 [=============>................] - ETA: 0s - loss: 0.0048 - accuracy: 0.9995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 25]\n",
            "INFO:flwr:[ROUND 25]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r105/147 [====================>.........] - ETA: 0s - loss: 0.0045 - accuracy: 0.9997\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r144/147 [============================>.] - ETA: 0s - loss: 0.0092 - accuracy: 0.9983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - 0s 1ms/step - loss: 0.0090 - accuracy: 0.9983\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 2s - loss: 43.7218 - accuracy: 0.0938\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 3ms/step - loss: 45.0969 - accuracy: 0.0615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (25, 2.0931499004364014, {'loss': 2.0931499004364014, 'accuracy': 0.9592432379722595, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99532   0.55837   0.71540      7230\\n           1    0.95729   0.99973   0.97805     71579\\n\\n    accuracy                        0.95924     78809\\n   macro avg    0.97630   0.77905   0.84672     78809\\nweighted avg    0.96077   0.95924   0.95395     78809\\n'}, 2183.3881652570008)\n",
            "INFO:flwr:fit progress: (25, 2.0931499004364014, {'loss': 2.0931499004364014, 'accuracy': 0.9592432379722595, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99532   0.55837   0.71540      7230\\n           1    0.95729   0.99973   0.97805     71579\\n\\n    accuracy                        0.95924     78809\\n   macro avg    0.97630   0.77905   0.84672     78809\\nweighted avg    0.96077   0.95924   0.95395     78809\\n'}, 2183.3881652570008)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/147 [..............................] - ETA: 51s - loss: 1.5736e-05 - accuracy: 1.0000\n",
            " 40/147 [=======>......................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            " 81/147 [===============>..............] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "123/147 [========================>.....] - ETA: 0s - loss: 0.0030 - accuracy: 0.9997    \n",
            "147/147 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9996\n",
            "  1/126 [..............................] - ETA: 24s - loss: 0.0086 - accuracy: 1.0000\n",
            " 77/126 [=================>............] - ETA: 0s - loss: 0.9842 - accuracy: 0.9813\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 1.1390 - accuracy: 0.9790\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 26]\n",
            "INFO:flwr:[ROUND 26]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 1s - loss: 44.8892 - accuracy: 0.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 2ms/step - loss: 45.6580 - accuracy: 0.0615\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 6s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (26, 2.107858419418335, {'loss': 2.107858419418335, 'accuracy': 0.9604232907295227, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99590   0.57095   0.72580      7230\\n           1    0.95845   0.99976   0.97867     71579\\n\\n    accuracy                        0.96042     78809\\n   macro avg    0.97718   0.78536   0.85224     78809\\nweighted avg    0.96189   0.96042   0.95547     78809\\n'}, 2270.2306692780003)\n",
            "INFO:flwr:fit progress: (26, 2.107858419418335, {'loss': 2.107858419418335, 'accuracy': 0.9604232907295227, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99590   0.57095   0.72580      7230\\n           1    0.95845   0.99976   0.97867     71579\\n\\n    accuracy                        0.96042     78809\\n   macro avg    0.97718   0.78536   0.85224     78809\\nweighted avg    0.96189   0.96042   0.95547     78809\\n'}, 2270.2306692780003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 45.8946 - accuracy: 0.1068\n",
            "  1/147 [..............................] - ETA: 32s - loss: 1.3906e-05 - accuracy: 1.0000\n",
            " 78/147 [==============>...............] - ETA: 0s - loss: 7.3909e-04 - accuracy: 1.0000\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0038 - accuracy: 0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 27]\n",
            "INFO:flwr:[ROUND 27]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/126 [..............................] - ETA: 26s - loss: 0.1358 - accuracy: 0.9688\n",
            " 73/126 [================>.............] - ETA: 0s - loss: 1.0373 - accuracy: 0.9760\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 1.1667 - accuracy: 0.9743\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (27, 2.0857748985290527, {'loss': 2.0857748985290527, 'accuracy': 0.9613242149353027, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99573   0.58091   0.73375      7230\\n           1    0.95938   0.99975   0.97915     71579\\n\\n    accuracy                        0.96132     78809\\n   macro avg    0.97756   0.79033   0.85645     78809\\nweighted avg    0.96271   0.96132   0.95663     78809\\n'}, 2358.7912963440003)\n",
            "INFO:flwr:fit progress: (27, 2.0857748985290527, {'loss': 2.0857748985290527, 'accuracy': 0.9613242149353027, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99573   0.58091   0.73375      7230\\n           1    0.95938   0.99975   0.97915     71579\\n\\n    accuracy                        0.96132     78809\\n   macro avg    0.97756   0.79033   0.85645     78809\\nweighted avg    0.96271   0.96132   0.95663     78809\\n'}, 2358.7912963440003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 45.3893 - accuracy: 0.1165\n",
            "  1/126 [..............................] - ETA: 31s - loss: 2.5128e-04 - accuracy: 1.0000\n",
            " 70/126 [===============>..............] - ETA: 0s - loss: 1.0931 - accuracy: 0.9826\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 1.2528 - accuracy: 0.9800\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 28]\n",
            "INFO:flwr:[ROUND 28]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/147 [..............................] - ETA: 32s - loss: 1.0434e-05 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 35/147 [======>.......................] - ETA: 0s - loss: 4.5359e-04 - accuracy: 1.0000 \n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 70/147 [=============>................] - ETA: 0s - loss: 4.0868e-04 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r106/147 [====================>.........] - ETA: 0s - loss: 3.7172e-04 - accuracy: 1.0000\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r144/147 [============================>.] - ETA: 0s - loss: 0.0034 - accuracy: 0.9996    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - 0s 1ms/step - loss: 0.0033 - accuracy: 0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (28, 2.174936294555664, {'loss': 2.174936294555664, 'accuracy': 0.9608293175697327, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99522   0.57580   0.72952      7230\\n           1    0.95890   0.99972   0.97889     71579\\n\\n    accuracy                        0.96083     78809\\n   macro avg    0.97706   0.78776   0.85420     78809\\nweighted avg    0.96223   0.96083   0.95601     78809\\n'}, 2448.745764798)\n",
            "INFO:flwr:fit progress: (28, 2.174936294555664, {'loss': 2.174936294555664, 'accuracy': 0.9608293175697327, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99522   0.57580   0.72952      7230\\n           1    0.95890   0.99972   0.97889     71579\\n\\n    accuracy                        0.96083     78809\\n   macro avg    0.97706   0.78776   0.85420     78809\\nweighted avg    0.96223   0.96083   0.95601     78809\\n'}, 2448.745764798)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/126 [..............................] - ETA: 43s - loss: 2.6961e-04 - accuracy: 1.0000\n",
            " 40/126 [========>.....................] - ETA: 0s - loss: 0.9419 - accuracy: 0.9836\n",
            " 72/126 [================>.............] - ETA: 0s - loss: 1.0246 - accuracy: 0.9813\n",
            "108/126 [========================>.....] - ETA: 0s - loss: 1.1341 - accuracy: 0.9800\n",
            "126/126 [==============================] - 1s 3ms/step - loss: 1.1457 - accuracy: 0.9798\n",
            "  1/147 [..............................] - ETA: 33s - loss: 1.3318e-05 - accuracy: 1.0000\n",
            " 71/147 [=============>................] - ETA: 0s - loss: 0.0016 - accuracy: 1.0000\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0048 - accuracy: 0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 29]\n",
            "INFO:flwr:[ROUND 29]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 2s - loss: 46.8538 - accuracy: 0.1562\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 3ms/step - loss: 47.4609 - accuracy: 0.1100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (29, 2.19726824760437, {'loss': 2.19726824760437, 'accuracy': 0.9602075815200806, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99564   0.56874   0.72394      7230\\n           1    0.95825   0.99975   0.97856     71579\\n\\n    accuracy                        0.96021     78809\\n   macro avg    0.97694   0.78424   0.85125     78809\\nweighted avg    0.96168   0.96021   0.95520     78809\\n'}, 2539.872717735)\n",
            "INFO:flwr:fit progress: (29, 2.19726824760437, {'loss': 2.19726824760437, 'accuracy': 0.9602075815200806, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99564   0.56874   0.72394      7230\\n           1    0.95825   0.99975   0.97856     71579\\n\\n    accuracy                        0.96021     78809\\n   macro avg    0.97694   0.78424   0.85125     78809\\nweighted avg    0.96168   0.96021   0.95520     78809\\n'}, 2539.872717735)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 32/147 [=====>........................] - ETA: 0s - loss: 0.0031 - accuracy: 1.0000     \n",
            " 91/147 [=================>............] - ETA: 0s - loss: 0.0026 - accuracy: 1.0000\n",
            "147/147 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 0.9994\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 47.8728 - accuracy: 0.0874\n",
            " 26/126 [=====>........................] - ETA: 0s - loss: 1.1133 - accuracy: 0.9796     \n",
            " 76/126 [=================>............] - ETA: 0s - loss: 1.0642 - accuracy: 0.9815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 30]\n",
            "INFO:flwr:[ROUND 30]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/126 [======================>.......] - ETA: 0s - loss: 1.1658 - accuracy: 0.9800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r123/126 [============================>.] - ETA: 0s - loss: 1.1963 - accuracy: 0.9799\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 1s 2ms/step - loss: 1.2198 - accuracy: 0.9793\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (30, 2.224874973297119, {'loss': 2.224874973297119, 'accuracy': 0.9601060748100281, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99515   0.56791   0.72314      7230\\n           1    0.95817   0.99972   0.97850     71579\\n\\n    accuracy                        0.96011     78809\\n   macro avg    0.97666   0.78382   0.85082     78809\\nweighted avg    0.96156   0.96011   0.95508     78809\\n'}, 2631.340167513001)\n",
            "INFO:flwr:fit progress: (30, 2.224874973297119, {'loss': 2.224874973297119, 'accuracy': 0.9601060748100281, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99515   0.56791   0.72314      7230\\n           1    0.95817   0.99972   0.97850     71579\\n\\n    accuracy                        0.96011     78809\\n   macro avg    0.97666   0.78382   0.85082     78809\\nweighted avg    0.96156   0.96011   0.95508     78809\\n'}, 2631.340167513001)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 48.4844 - accuracy: 0.0841\n",
            "  1/126 [..............................] - ETA: 25s - loss: 2.1104e-04 - accuracy: 1.0000\n",
            " 75/126 [================>.............] - ETA: 0s - loss: 1.0821 - accuracy: 0.9817\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 31]\n",
            "INFO:flwr:[ROUND 31]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r113/126 [=========================>....] - ETA: 0s - loss: 1.2481 - accuracy: 0.9795\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 0s 1ms/step - loss: 1.2616 - accuracy: 0.9793\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/147 [..............................] - ETA: 31s - loss: 9.8596e-06 - accuracy: 1.0000\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 38/147 [======>.......................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 74/147 [==============>...............] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r113/147 [======================>.......] - ETA: 0s - loss: 0.0035 - accuracy: 0.9997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.9996\n",
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (31, 2.2805228233337402, {'loss': 2.2805228233337402, 'accuracy': 0.9597127437591553, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99487   0.56376   0.71970      7230\\n           1    0.95778   0.99971   0.97830     71579\\n\\n    accuracy                        0.95971     78809\\n   macro avg    0.97633   0.78173   0.84900     78809\\nweighted avg    0.96119   0.95971   0.95457     78809\\n'}, 2718.1553273340005)\n",
            "INFO:flwr:fit progress: (31, 2.2805228233337402, {'loss': 2.2805228233337402, 'accuracy': 0.9597127437591553, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99487   0.56376   0.71970      7230\\n           1    0.95778   0.99971   0.97830     71579\\n\\n    accuracy                        0.95971     78809\\n   macro avg    0.97633   0.78173   0.84900     78809\\nweighted avg    0.96119   0.95971   0.95457     78809\\n'}, 2718.1553273340005)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/147 [..............................] - ETA: 43s - loss: 8.2408e-06 - accuracy: 1.0000\n",
            " 43/147 [=======>......................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000    \n",
            " 90/147 [=================>............] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "129/147 [=========================>....] - ETA: 0s - loss: 0.0031 - accuracy: 0.9998    \n",
            "147/147 [==============================] - 1s 2ms/step - loss: 0.0042 - accuracy: 0.9996\n",
            "  1/126 [..............................] - ETA: 38s - loss: 1.7286e-04 - accuracy: 1.0000\n",
            " 45/126 [=========>....................] - ETA: 0s - loss: 0.9877 - accuracy: 0.9840\n",
            " 97/126 [======================>.......] - ETA: 0s - loss: 1.2161 - accuracy: 0.9803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 32]\n",
            "INFO:flwr:[ROUND 32]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r119/126 [===========================>..] - ETA: 0s - loss: 1.2841 - accuracy: 0.9798\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 1s 2ms/step - loss: 1.3033 - accuracy: 0.9793\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 2s - loss: 49.8898 - accuracy: 0.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 3ms/step - loss: 49.8293 - accuracy: 0.0744\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 5s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (32, 2.3319032192230225, {'loss': 2.3319032192230225, 'accuracy': 0.9589640498161316, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99554   0.55519   0.71284      7230\\n           1    0.95699   0.99975   0.97790     71579\\n\\n    accuracy                        0.95896     78809\\n   macro avg    0.97626   0.77747   0.84537     78809\\nweighted avg    0.96053   0.95896   0.95359     78809\\n'}, 2803.3205908890004)\n",
            "INFO:flwr:fit progress: (32, 2.3319032192230225, {'loss': 2.3319032192230225, 'accuracy': 0.9589640498161316, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99554   0.55519   0.71284      7230\\n           1    0.95699   0.99975   0.97790     71579\\n\\n    accuracy                        0.95896     78809\\n   macro avg    0.97626   0.77747   0.84537     78809\\nweighted avg    0.96053   0.95896   0.95359     78809\\n'}, 2803.3205908890004)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 51.0580 - accuracy: 0.0550\n",
            " 37/147 [======>.......................] - ETA: 0s - loss: 0.0014 - accuracy: 1.0000     \n",
            "109/147 [=====================>........] - ETA: 0s - loss: 0.0035 - accuracy: 0.9997\n",
            "145/147 [============================>.] - ETA: 0s - loss: 0.0045 - accuracy: 0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 33]\n",
            "INFO:flwr:[ROUND 33]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - 0s 1ms/step - loss: 0.0045 - accuracy: 0.9996\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/126 [..............................] - ETA: 25s - loss: 1.8190e-04 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 39/126 [========>.....................] - ETA: 0s - loss: 1.0747 - accuracy: 0.9832     \n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 75/126 [================>.............] - ETA: 0s - loss: 1.0938 - accuracy: 0.9821\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r113/126 [=========================>....] - ETA: 0s - loss: 1.2629 - accuracy: 0.9801\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 0s 1ms/step - loss: 1.2757 - accuracy: 0.9798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (33, 2.2670748233795166, {'loss': 2.2670748233795166, 'accuracy': 0.9584565162658691, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99425   0.55035   0.70851      7230\\n           1    0.95654   0.99968   0.97763     71579\\n\\n    accuracy                        0.95846     78809\\n   macro avg    0.97540   0.77501   0.84307     78809\\nweighted avg    0.96000   0.95846   0.95294     78809\\n'}, 2889.0250629970005)\n",
            "INFO:flwr:fit progress: (33, 2.2670748233795166, {'loss': 2.2670748233795166, 'accuracy': 0.9584565162658691, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99425   0.55035   0.70851      7230\\n           1    0.95654   0.99968   0.97763     71579\\n\\n    accuracy                        0.95846     78809\\n   macro avg    0.97540   0.77501   0.84307     78809\\nweighted avg    0.96000   0.95846   0.95294     78809\\n'}, 2889.0250629970005)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 20/147 [===>..........................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000     \n",
            " 62/147 [===========>..................] - ETA: 0s - loss: 0.0012 - accuracy: 1.0000\n",
            "108/147 [=====================>........] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000\n",
            "147/147 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9996\n",
            "10/10 [==============================] - 0s 3ms/step - loss: 49.7592 - accuracy: 0.0421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 34]\n",
            "INFO:flwr:[ROUND 34]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  1/126 [..............................] - ETA: 31s - loss: 1.5671e-04 - accuracy: 1.0000\n",
            " 71/126 [===============>..............] - ETA: 0s - loss: 1.1756 - accuracy: 0.9815\n",
            "126/126 [==============================] - 0s 2ms/step - loss: 1.3345 - accuracy: 0.9798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 8s 3ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (34, 2.378068447113037, {'loss': 2.378068447113037, 'accuracy': 0.9589767456054688, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99554   0.55533   0.71295      7230\\n           1    0.95700   0.99975   0.97791     71579\\n\\n    accuracy                        0.95898     78809\\n   macro avg    0.97627   0.77754   0.84543     78809\\nweighted avg    0.96054   0.95898   0.95360     78809\\n'}, 2986.9826407890005)\n",
            "INFO:flwr:fit progress: (34, 2.378068447113037, {'loss': 2.378068447113037, 'accuracy': 0.9589767456054688, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99554   0.55533   0.71295      7230\\n           1    0.95700   0.99975   0.97791     71579\\n\\n    accuracy                        0.95898     78809\\n   macro avg    0.97627   0.77754   0.84543     78809\\nweighted avg    0.96054   0.95898   0.95360     78809\\n'}, 2986.9826407890005)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 37/147 [======>.......................] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000     \n",
            "109/147 [=====================>........] - ETA: 0s - loss: 0.0036 - accuracy: 0.9997\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0046 - accuracy: 0.9996\n",
            "  1/126 [..............................] - ETA: 30s - loss: 1.8895e-04 - accuracy: 1.0000\n",
            " 66/126 [==============>...............] - ETA: 0s - loss: 1.0611 - accuracy: 0.9830\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 35]\n",
            "INFO:flwr:[ROUND 35]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r103/126 [=======================>......] - ETA: 0s - loss: 1.2705 - accuracy: 0.9800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 0s 1ms/step - loss: 1.2937 - accuracy: 0.9795\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 2s - loss: 52.2991 - accuracy: 0.0625\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 2ms/step - loss: 52.2748 - accuracy: 0.0583\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (35, 2.4169411659240723, {'loss': 2.4169411659240723, 'accuracy': 0.9594462513923645, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99436   0.56113   0.71742      7230\\n           1    0.95754   0.99968   0.97816     71579\\n\\n    accuracy                        0.95945     78809\\n   macro avg    0.97595   0.78041   0.84779     78809\\nweighted avg    0.96092   0.95945   0.95424     78809\\n'}, 3076.8717505310005)\n",
            "INFO:flwr:fit progress: (35, 2.4169411659240723, {'loss': 2.4169411659240723, 'accuracy': 0.9594462513923645, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99436   0.56113   0.71742      7230\\n           1    0.95754   0.99968   0.97816     71579\\n\\n    accuracy                        0.95945     78809\\n   macro avg    0.97595   0.78041   0.84779     78809\\nweighted avg    0.96092   0.95945   0.95424     78809\\n'}, 3076.8717505310005)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 22/126 [====>.........................] - ETA: 0s - loss: 1.0709 - accuracy: 0.9815     \n",
            " 70/126 [===============>..............] - ETA: 0s - loss: 1.0080 - accuracy: 0.9826\n",
            "115/126 [==========================>...] - ETA: 0s - loss: 1.1238 - accuracy: 0.9810\n",
            "126/126 [==============================] - 1s 2ms/step - loss: 1.1549 - accuracy: 0.9803\n",
            "  1/147 [..............................] - ETA: 46s - loss: 9.2894e-06 - accuracy: 1.0000\n",
            " 65/147 [============>.................] - ETA: 0s - loss: 0.0027 - accuracy: 1.0000\n",
            "147/147 [==============================] - 1s 1ms/step - loss: 0.0060 - accuracy: 0.9994\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 36]\n",
            "INFO:flwr:[ROUND 36]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 2s - loss: 53.5506 - accuracy: 0.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 2ms/step - loss: 53.1585 - accuracy: 0.0680\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (36, 2.565579891204834, {'loss': 2.565579891204834, 'accuracy': 0.9582027196884155, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99572   0.54675   0.70589      7230\\n           1    0.95621   0.99976   0.97750     71579\\n\\n    accuracy                        0.95820     78809\\n   macro avg    0.97597   0.77326   0.84170     78809\\nweighted avg    0.95984   0.95820   0.95259     78809\\n'}, 3163.9500447580003)\n",
            "INFO:flwr:fit progress: (36, 2.565579891204834, {'loss': 2.565579891204834, 'accuracy': 0.9582027196884155, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99572   0.54675   0.70589      7230\\n           1    0.95621   0.99976   0.97750     71579\\n\\n    accuracy                        0.95820     78809\\n   macro avg    0.97597   0.77326   0.84170     78809\\nweighted avg    0.95984   0.95820   0.95259     78809\\n'}, 3163.9500447580003)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 39/126 [========>.....................] - ETA: 0s - loss: 1.0912 - accuracy: 0.9824     \n",
            "113/126 [=========================>....] - ETA: 0s - loss: 1.2828 - accuracy: 0.9798\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 1.2963 - accuracy: 0.9795\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 56.5871 - accuracy: 0.0388\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 37]\n",
            "INFO:flwr:[ROUND 37]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/147 [..............................] - ETA: 32s - loss: 9.9881e-06 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 36/147 [======>.......................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000     \n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 73/147 [=============>................] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r111/147 [=====================>........] - ETA: 0s - loss: 0.0032 - accuracy: 0.9997\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r147/147 [==============================] - 0s 1ms/step - loss: 0.0041 - accuracy: 0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (37, 2.5098161697387695, {'loss': 2.5098161697387695, 'accuracy': 0.9584565162658691, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99524   0.54979   0.70830      7230\\n           1    0.95649   0.99973   0.97764     71579\\n\\n    accuracy                        0.95846     78809\\n   macro avg    0.97587   0.77476   0.84297     78809\\nweighted avg    0.96005   0.95846   0.95293     78809\\n'}, 3259.1127630090004)\n",
            "INFO:flwr:fit progress: (37, 2.5098161697387695, {'loss': 2.5098161697387695, 'accuracy': 0.9584565162658691, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99524   0.54979   0.70830      7230\\n           1    0.95649   0.99973   0.97764     71579\\n\\n    accuracy                        0.95846     78809\\n   macro avg    0.97587   0.77476   0.84297     78809\\nweighted avg    0.96005   0.95846   0.95293     78809\\n'}, 3259.1127630090004)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 35/126 [=======>......................] - ETA: 0s - loss: 1.0650 - accuracy: 0.9812     \n",
            "102/126 [=======================>......] - ETA: 0s - loss: 1.1941 - accuracy: 0.9801\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 1.2213 - accuracy: 0.9795\n",
            "  1/147 [..............................] - ETA: 33s - loss: 7.7191e-06 - accuracy: 1.0000\n",
            " 72/147 [=============>................] - ETA: 0s - loss: 0.0018 - accuracy: 1.0000\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0052 - accuracy: 0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 38]\n",
            "INFO:flwr:[ROUND 38]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r 1/10 [==>...........................] - ETA: 1s - loss: 55.3627 - accuracy: 0.0312\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r10/10 [==============================] - 0s 2ms/step - loss: 55.3473 - accuracy: 0.0421\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 4s 1ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (38, 2.596853494644165, {'loss': 2.596853494644165, 'accuracy': 0.956997275352478, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.96535   0.55104   0.70159      7230\\n           1    0.95654   0.99800   0.97683     71579\\n\\n    accuracy                        0.95700     78809\\n   macro avg    0.96094   0.77452   0.83921     78809\\nweighted avg    0.95734   0.95700   0.95158     78809\\n'}, 3345.350205642)\n",
            "INFO:flwr:fit progress: (38, 2.596853494644165, {'loss': 2.596853494644165, 'accuracy': 0.956997275352478, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.96535   0.55104   0.70159      7230\\n           1    0.95654   0.99800   0.97683     71579\\n\\n    accuracy                        0.95700     78809\\n   macro avg    0.96094   0.77452   0.83921     78809\\nweighted avg    0.95734   0.95700   0.95158     78809\\n'}, 3345.350205642)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 57.1055 - accuracy: 0.0453\n",
            " 24/126 [====>.........................] - ETA: 0s - loss: 1.0434 - accuracy: 0.9831     \n",
            " 66/126 [==============>...............] - ETA: 0s - loss: 1.0051 - accuracy: 0.9834\n",
            "115/126 [==========================>...] - ETA: 0s - loss: 1.1928 - accuracy: 0.9807\n",
            "126/126 [==============================] - 1s 2ms/step - loss: 1.2268 - accuracy: 0.9800\n",
            "  1/147 [..............................] - ETA: 50s - loss: 7.6261e-06 - accuracy: 1.0000\n",
            " 48/147 [========>.....................] - ETA: 0s - loss: 0.0063 - accuracy: 0.9967\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 39]\n",
            "INFO:flwr:[ROUND 39]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 71/147 [=============>................] - ETA: 0s - loss: 0.0067 - accuracy: 0.9960\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 95/147 [==================>...........] - ETA: 0s - loss: 0.0066 - accuracy: 0.9964\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r107/147 [====================>.........] - ETA: 0s - loss: 0.0061 - accuracy: 0.9965\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r132/147 [=========================>....] - ETA: 0s - loss: 0.0105 - accuracy: 0.9957\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "147/147 [==============================] - 1s 2ms/step - loss: 0.0109 - accuracy: 0.9957\n",
            "2463/2463 [==============================] - 5s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (39, 2.764934539794922, {'loss': 2.764934539794922, 'accuracy': 0.9578855037689209, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99645   0.54288   0.70284      7230\\n           1    0.95586   0.99980   0.97734     71579\\n\\n    accuracy                        0.95789     78809\\n   macro avg    0.97615   0.77134   0.84009     78809\\nweighted avg    0.95958   0.95789   0.95215     78809\\n'}, 3434.2659476140007)\n",
            "INFO:flwr:fit progress: (39, 2.764934539794922, {'loss': 2.764934539794922, 'accuracy': 0.9578855037689209, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.99645   0.54288   0.70284      7230\\n           1    0.95586   0.99980   0.97734     71579\\n\\n    accuracy                        0.95789     78809\\n   macro avg    0.97615   0.77134   0.84009     78809\\nweighted avg    0.95958   0.95789   0.95215     78809\\n'}, 3434.2659476140007)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 36/126 [=======>......................] - ETA: 0s - loss: 1.2911 - accuracy: 0.9818     \n",
            "103/126 [=======================>......] - ETA: 0s - loss: 1.3929 - accuracy: 0.9800\n",
            "126/126 [==============================] - 0s 1ms/step - loss: 1.4167 - accuracy: 0.9795\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 61.0058 - accuracy: 0.0324\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [ROUND 40]\n",
            "INFO:flwr:[ROUND 40]\n",
            "\u001b[92mINFO \u001b[0m:      configure_fit: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_fit: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 38/147 [======>.......................] - ETA: 0s - loss: 0.0011 - accuracy: 1.0000     \n",
            "115/147 [======================>.......] - ETA: 0s - loss: 0.0031 - accuracy: 0.9997    \n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0039 - accuracy: 0.9996\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_fit: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_fit: received 3 results and 0 failures\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2463/2463 [==============================] - 6s 2ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      fit progress: (40, 2.746053457260132, {'loss': 2.746053457260132, 'accuracy': 0.956794261932373, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.95612   0.55450   0.70192      7230\\n           1    0.95683   0.99743   0.97671     71579\\n\\n    accuracy                        0.95679     78809\\n   macro avg    0.95647   0.77596   0.83931     78809\\nweighted avg    0.95677   0.95679   0.95150     78809\\n'}, 3519.479636856)\n",
            "INFO:flwr:fit progress: (40, 2.746053457260132, {'loss': 2.746053457260132, 'accuracy': 0.956794261932373, 'Centralised report': '              precision    recall  f1-score   support\\n\\n           0    0.95612   0.55450   0.70192      7230\\n           1    0.95683   0.99743   0.97671     71579\\n\\n    accuracy                        0.95679     78809\\n   macro avg    0.95647   0.77596   0.83931     78809\\nweighted avg    0.95677   0.95679   0.95150     78809\\n'}, 3519.479636856)\n",
            "\u001b[92mINFO \u001b[0m:      configure_evaluate: strategy sampled 3 clients (out of 3)\n",
            "INFO:flwr:configure_evaluate: strategy sampled 3 clients (out of 3)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/10 [==>...........................] - ETA: 1s - loss: 61.6152 - accuracy: 0.0938\n",
            "10/10 [==============================] - 0s 2ms/step - loss: 60.4901 - accuracy: 0.0615\n",
            "  1/147 [..............................] - ETA: 31s - loss: 7.3350e-06 - accuracy: 1.0000\n",
            " 77/147 [==============>...............] - ETA: 0s - loss: 0.0075 - accuracy: 0.9955\n",
            "147/147 [==============================] - 0s 1ms/step - loss: 0.0118 - accuracy: 0.9936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      aggregate_evaluate: received 3 results and 0 failures\n",
            "INFO:flwr:aggregate_evaluate: received 3 results and 0 failures\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n",
            "\u001b[92mINFO \u001b[0m:      [SUMMARY]\n",
            "INFO:flwr:[SUMMARY]\n",
            "\u001b[92mINFO \u001b[0m:      Run finished 40 rounds in 3522.98s\n",
            "INFO:flwr:Run finished 40 rounds in 3522.98s\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \r  1/126 [..............................] - ETA: 28s - loss: 1.4114e-04 - accuracy: 1.0000\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 34/126 [=======>......................] - ETA: 0s - loss: 1.0628 - accuracy: 0.9816     \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r 71/126 [===============>..............] - ETA: 0s - loss: 1.0408 - accuracy: 0.9815\n",
            "\u001b[2m\u001b[36m(ClientAppActor pid=33088)\u001b[0m \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r108/126 [========================>.....] - ETA: 0s - loss: 1.1712 - accuracy: 0.9800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r126/126 [==============================] - 0s 1ms/step - loss: 1.1839 - accuracy: 0.9798\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[92mINFO \u001b[0m:      History (loss, distributed):\n",
            "INFO:flwr:History (loss, distributed):\n",
            "\u001b[92mINFO \u001b[0m:      \t('\\tround 1: 0.7712968314143371\\n'\n",
            "INFO:flwr:\t('\\tround 1: 0.7712968314143371\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 1.3980555568297608\\n'\n",
            "INFO:flwr:\t '\\tround 2: 1.3980555568297608\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.841514330571477\\n'\n",
            "INFO:flwr:\t '\\tround 3: 0.841514330571477\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 1.0083308342658253\\n'\n",
            "INFO:flwr:\t '\\tround 4: 1.0083308342658253\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 5: 1.0743623389877495\\n'\n",
            "INFO:flwr:\t '\\tround 5: 1.0743623389877495\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 6: 1.1668602134843935\\n'\n",
            "INFO:flwr:\t '\\tround 6: 1.1668602134843935\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 7: 1.215002616845261\\n'\n",
            "INFO:flwr:\t '\\tround 7: 1.215002616845261\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 8: 1.2742194471178443\\n'\n",
            "INFO:flwr:\t '\\tround 8: 1.2742194471178443\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 9: 1.3526989253850716\\n'\n",
            "INFO:flwr:\t '\\tround 9: 1.3526989253850716\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 10: 1.3984747915502307\\n'\n",
            "INFO:flwr:\t '\\tround 10: 1.3984747915502307\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 11: 1.4169075453452402\\n'\n",
            "INFO:flwr:\t '\\tround 11: 1.4169075453452402\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 12: 1.5502049210046909\\n'\n",
            "INFO:flwr:\t '\\tround 12: 1.5502049210046909\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 13: 1.6313497151056466\\n'\n",
            "INFO:flwr:\t '\\tround 13: 1.6313497151056466\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 14: 1.6288423212944143\\n'\n",
            "INFO:flwr:\t '\\tround 14: 1.6288423212944143\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 15: 1.6938328925214885\\n'\n",
            "INFO:flwr:\t '\\tround 15: 1.6938328925214885\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 16: 1.8035740102732936\\n'\n",
            "INFO:flwr:\t '\\tround 16: 1.8035740102732936\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 17: 1.9127236827851721\\n'\n",
            "INFO:flwr:\t '\\tround 17: 1.9127236827851721\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 18: 1.900209161053722\\n'\n",
            "INFO:flwr:\t '\\tround 18: 1.900209161053722\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 19: 1.923471500754711\\n'\n",
            "INFO:flwr:\t '\\tround 19: 1.923471500754711\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 20: 1.8295946556395013\\n'\n",
            "INFO:flwr:\t '\\tround 20: 1.8295946556395013\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 21: 1.9393202594900727\\n'\n",
            "INFO:flwr:\t '\\tround 21: 1.9393202594900727\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 22: 1.9234571655103903\\n'\n",
            "INFO:flwr:\t '\\tround 22: 1.9234571655103903\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 23: 2.0537106707332997\\n'\n",
            "INFO:flwr:\t '\\tround 23: 2.0537106707332997\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 24: 1.9805335795419223\\n'\n",
            "INFO:flwr:\t '\\tround 24: 1.9805335795419223\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 25: 2.078535918873576\\n'\n",
            "INFO:flwr:\t '\\tround 25: 2.078535918873576\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 26: 2.0988866294877404\\n'\n",
            "INFO:flwr:\t '\\tround 26: 2.0988866294877404\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 27: 2.1196454968153278\\n'\n",
            "INFO:flwr:\t '\\tround 27: 2.1196454968153278\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 28: 2.1438667059931014\\n'\n",
            "INFO:flwr:\t '\\tround 28: 2.1438667059931014\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 29: 2.191605544441218\\n'\n",
            "INFO:flwr:\t '\\tround 29: 2.191605544441218\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 30: 2.230580830026116\\n'\n",
            "INFO:flwr:\t '\\tround 30: 2.230580830026116\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 31: 2.2951896417855777\\n'\n",
            "INFO:flwr:\t '\\tround 31: 2.2951896417855777\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 32: 2.3252523564917387\\n'\n",
            "INFO:flwr:\t '\\tround 32: 2.3252523564917387\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 33: 2.306788202670115\\n'\n",
            "INFO:flwr:\t '\\tround 33: 2.306788202670115\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 34: 2.3751305449705535\\n'\n",
            "INFO:flwr:\t '\\tround 34: 2.3751305449705535\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 35: 2.3443573676880267\\n'\n",
            "INFO:flwr:\t '\\tround 35: 2.3443573676880267\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 36: 2.524219707445546\\n'\n",
            "INFO:flwr:\t '\\tround 36: 2.524219707445546\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 37: 2.4487152953387668\\n'\n",
            "INFO:flwr:\t '\\tround 37: 2.4487152953387668\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 38: 2.514610880708106\\n'\n",
            "INFO:flwr:\t '\\tround 38: 2.514610880708106\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 39: 2.7295863758107752\\n'\n",
            "INFO:flwr:\t '\\tround 39: 2.7295863758107752\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 40: 2.6122243247427486\\n')History (loss, centralized):\n",
            "INFO:flwr:\t '\\tround 40: 2.6122243247427486\\n')History (loss, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t('\\tround 0: 0.5633272528648376\\n'\n",
            "INFO:flwr:\t('\\tround 0: 0.5633272528648376\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 1: 0.593224823474884\\n'\n",
            "INFO:flwr:\t '\\tround 1: 0.593224823474884\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 2: 0.8698111176490784\\n'\n",
            "INFO:flwr:\t '\\tround 2: 0.8698111176490784\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 3: 0.9248741269111633\\n'\n",
            "INFO:flwr:\t '\\tround 3: 0.9248741269111633\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 4: 1.1406844854354858\\n'\n",
            "INFO:flwr:\t '\\tround 4: 1.1406844854354858\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 5: 1.1973904371261597\\n'\n",
            "INFO:flwr:\t '\\tround 5: 1.1973904371261597\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 6: 1.2157864570617676\\n'\n",
            "INFO:flwr:\t '\\tround 6: 1.2157864570617676\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 7: 1.2410391569137573\\n'\n",
            "INFO:flwr:\t '\\tround 7: 1.2410391569137573\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 8: 1.2876172065734863\\n'\n",
            "INFO:flwr:\t '\\tround 8: 1.2876172065734863\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 9: 1.3448415994644165\\n'\n",
            "INFO:flwr:\t '\\tround 9: 1.3448415994644165\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 10: 1.377259373664856\\n'\n",
            "INFO:flwr:\t '\\tround 10: 1.377259373664856\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 11: 1.3616935014724731\\n'\n",
            "INFO:flwr:\t '\\tround 11: 1.3616935014724731\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 12: 1.5094852447509766\\n'\n",
            "INFO:flwr:\t '\\tround 12: 1.5094852447509766\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 13: 1.6048648357391357\\n'\n",
            "INFO:flwr:\t '\\tround 13: 1.6048648357391357\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 14: 1.6292552947998047\\n'\n",
            "INFO:flwr:\t '\\tround 14: 1.6292552947998047\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 15: 1.6762031316757202\\n'\n",
            "INFO:flwr:\t '\\tround 15: 1.6762031316757202\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 16: 1.7921123504638672\\n'\n",
            "INFO:flwr:\t '\\tround 16: 1.7921123504638672\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 17: 1.8987363576889038\\n'\n",
            "INFO:flwr:\t '\\tround 17: 1.8987363576889038\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 18: 1.9275610446929932\\n'\n",
            "INFO:flwr:\t '\\tround 18: 1.9275610446929932\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 19: 1.927960753440857\\n'\n",
            "INFO:flwr:\t '\\tround 19: 1.927960753440857\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 20: 1.8559390306472778\\n'\n",
            "INFO:flwr:\t '\\tround 20: 1.8559390306472778\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 21: 1.9612752199172974\\n'\n",
            "INFO:flwr:\t '\\tround 21: 1.9612752199172974\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 22: 1.9139714241027832\\n'\n",
            "INFO:flwr:\t '\\tround 22: 1.9139714241027832\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 23: 2.0630550384521484\\n'\n",
            "INFO:flwr:\t '\\tround 23: 2.0630550384521484\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 24: 2.05899715423584\\n'\n",
            "INFO:flwr:\t '\\tround 24: 2.05899715423584\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 25: 2.0931499004364014\\n'\n",
            "INFO:flwr:\t '\\tround 25: 2.0931499004364014\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 26: 2.107858419418335\\n'\n",
            "INFO:flwr:\t '\\tround 26: 2.107858419418335\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 27: 2.0857748985290527\\n'\n",
            "INFO:flwr:\t '\\tround 27: 2.0857748985290527\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 28: 2.174936294555664\\n'\n",
            "INFO:flwr:\t '\\tround 28: 2.174936294555664\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 29: 2.19726824760437\\n'\n",
            "INFO:flwr:\t '\\tround 29: 2.19726824760437\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 30: 2.224874973297119\\n'\n",
            "INFO:flwr:\t '\\tround 30: 2.224874973297119\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 31: 2.2805228233337402\\n'\n",
            "INFO:flwr:\t '\\tround 31: 2.2805228233337402\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 32: 2.3319032192230225\\n'\n",
            "INFO:flwr:\t '\\tround 32: 2.3319032192230225\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 33: 2.2670748233795166\\n'\n",
            "INFO:flwr:\t '\\tround 33: 2.2670748233795166\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 34: 2.378068447113037\\n'\n",
            "INFO:flwr:\t '\\tround 34: 2.378068447113037\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 35: 2.4169411659240723\\n'\n",
            "INFO:flwr:\t '\\tround 35: 2.4169411659240723\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 36: 2.565579891204834\\n'\n",
            "INFO:flwr:\t '\\tround 36: 2.565579891204834\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 37: 2.5098161697387695\\n'\n",
            "INFO:flwr:\t '\\tround 37: 2.5098161697387695\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 38: 2.596853494644165\\n'\n",
            "INFO:flwr:\t '\\tround 38: 2.596853494644165\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 39: 2.764934539794922\\n'\n",
            "INFO:flwr:\t '\\tround 39: 2.764934539794922\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t '\\tround 40: 2.746053457260132\\n')History (metrics, distributed, evaluate):\n",
            "INFO:flwr:\t '\\tround 40: 2.746053457260132\\n')History (metrics, distributed, evaluate):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'agg_accuracy': [(1, 0.8097409112897794),\n",
            "INFO:flwr:\t{'agg_accuracy': [(1, 0.8097409112897794),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (2, 0.7421327637798275),\n",
            "INFO:flwr:\t                  (2, 0.7421327637798275),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (3, 0.8969198405994505),\n",
            "INFO:flwr:\t                  (3, 0.8969198405994505),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (4, 0.8974758373579843),\n",
            "INFO:flwr:\t                  (4, 0.8974758373579843),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (5, 0.8973645930340329),\n",
            "INFO:flwr:\t                  (5, 0.8973645930340329),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (6, 0.8972533972792839),\n",
            "INFO:flwr:\t                  (6, 0.8972533972792839),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (7, 0.8975870174866464),\n",
            "INFO:flwr:\t                  (7, 0.8975870174866464),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (8, 0.8984765964142343),\n",
            "INFO:flwr:\t                  (8, 0.8984765964142343),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (9, 0.9013677101226454),\n",
            "INFO:flwr:\t                  (9, 0.9013677101226454),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (10, 0.8986989661751289),\n",
            "INFO:flwr:\t                  (10, 0.8986989661751289),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (11, 0.899254948595044),\n",
            "INFO:flwr:\t                  (11, 0.899254948595044),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (12, 0.901478923984799),\n",
            "INFO:flwr:\t                  (12, 0.901478923984799),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (13, 0.9012565443226602),\n",
            "INFO:flwr:\t                  (13, 0.9012565443226602),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (14, 0.9051484497744343),\n",
            "INFO:flwr:\t                  (14, 0.9051484497744343),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (15, 0.9540753956284735),\n",
            "INFO:flwr:\t                  (15, 0.9540753956284735),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (16, 0.9599688590487556),\n",
            "INFO:flwr:\t                  (16, 0.9599688590487556),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (17, 0.9584120743446417),\n",
            "INFO:flwr:\t                  (17, 0.9584120743446417),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (18, 0.9596352497799026),\n",
            "INFO:flwr:\t                  (18, 0.9596352497799026),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (19, 0.9589680889264092),\n",
            "INFO:flwr:\t                  (19, 0.9589680889264092),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (20, 0.960191241187241),\n",
            "INFO:flwr:\t                  (20, 0.960191241187241),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (21, 0.9603024601164191),\n",
            "INFO:flwr:\t                  (21, 0.9603024601164191),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (22, 0.9598576731952507),\n",
            "INFO:flwr:\t                  (22, 0.9598576731952507),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (23, 0.9579673086468163),\n",
            "INFO:flwr:\t                  (23, 0.9579673086468163),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (24, 0.9577449098449786),\n",
            "INFO:flwr:\t                  (24, 0.9577449098449786),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (25, 0.9581897074486541),\n",
            "INFO:flwr:\t                  (25, 0.9581897074486541),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (26, 0.9576337117414698),\n",
            "INFO:flwr:\t                  (26, 0.9576337117414698),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (27, 0.9605248376949138),\n",
            "INFO:flwr:\t                  (27, 0.9605248376949138),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (28, 0.960191243138327),\n",
            "INFO:flwr:\t                  (28, 0.960191243138327),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (29, 0.959079288327328),\n",
            "INFO:flwr:\t                  (29, 0.959079288327328),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (30, 0.9590792900224118),\n",
            "INFO:flwr:\t                  (30, 0.9590792900224118),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (31, 0.9587456971609087),\n",
            "INFO:flwr:\t                  (31, 0.9587456971609087),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (32, 0.9583008839311462),\n",
            "INFO:flwr:\t                  (32, 0.9583008839311462),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (33, 0.9578560934918092),\n",
            "INFO:flwr:\t                  (33, 0.9578560934918092),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (34, 0.9583009086726578),\n",
            "INFO:flwr:\t                  (34, 0.9583009086726578),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (35, 0.9588568736434009),\n",
            "INFO:flwr:\t                  (35, 0.9588568736434009),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (36, 0.9576337230776529),\n",
            "INFO:flwr:\t                  (36, 0.9576337230776529),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (37, 0.9577449206554869),\n",
            "INFO:flwr:\t                  (37, 0.9577449206554869),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (38, 0.9560769322460516),\n",
            "INFO:flwr:\t                  (38, 0.9560769322460516),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (39, 0.957411327921985),\n",
            "INFO:flwr:\t                  (39, 0.957411327921985),\n",
            "\u001b[92mINFO \u001b[0m:      \t                  (40, 0.9554097578451444)],\n",
            "INFO:flwr:\t                  (40, 0.9554097578451444)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'agg_loss': [(1, 0.7712968314143371),\n",
            "INFO:flwr:\t 'agg_loss': [(1, 0.7712968314143371),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 1.3980555568297608),\n",
            "INFO:flwr:\t              (2, 1.3980555568297608),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.841514330571477),\n",
            "INFO:flwr:\t              (3, 0.841514330571477),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 1.0083308342658253),\n",
            "INFO:flwr:\t              (4, 1.0083308342658253),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 1.0743623389877495),\n",
            "INFO:flwr:\t              (5, 1.0743623389877495),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (6, 1.1668602134843935),\n",
            "INFO:flwr:\t              (6, 1.1668602134843935),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (7, 1.215002616845261),\n",
            "INFO:flwr:\t              (7, 1.215002616845261),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (8, 1.2742194471178443),\n",
            "INFO:flwr:\t              (8, 1.2742194471178443),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (9, 1.3526989253850716),\n",
            "INFO:flwr:\t              (9, 1.3526989253850716),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (10, 1.3984747915502307),\n",
            "INFO:flwr:\t              (10, 1.3984747915502307),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (11, 1.4169075453452402),\n",
            "INFO:flwr:\t              (11, 1.4169075453452402),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (12, 1.5502049210046909),\n",
            "INFO:flwr:\t              (12, 1.5502049210046909),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (13, 1.6313497151056466),\n",
            "INFO:flwr:\t              (13, 1.6313497151056466),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (14, 1.6288423212944143),\n",
            "INFO:flwr:\t              (14, 1.6288423212944143),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (15, 1.6938328925214885),\n",
            "INFO:flwr:\t              (15, 1.6938328925214885),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (16, 1.8035740102732936),\n",
            "INFO:flwr:\t              (16, 1.8035740102732936),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (17, 1.9127236827851721),\n",
            "INFO:flwr:\t              (17, 1.9127236827851721),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (18, 1.900209161053722),\n",
            "INFO:flwr:\t              (18, 1.900209161053722),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (19, 1.923471500754711),\n",
            "INFO:flwr:\t              (19, 1.923471500754711),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (20, 1.8295946556395013),\n",
            "INFO:flwr:\t              (20, 1.8295946556395013),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (21, 1.9393202594900727),\n",
            "INFO:flwr:\t              (21, 1.9393202594900727),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (22, 1.9234571655103903),\n",
            "INFO:flwr:\t              (22, 1.9234571655103903),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (23, 2.0537106707332997),\n",
            "INFO:flwr:\t              (23, 2.0537106707332997),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (24, 1.9805335795419223),\n",
            "INFO:flwr:\t              (24, 1.9805335795419223),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (25, 2.078535918873576),\n",
            "INFO:flwr:\t              (25, 2.078535918873576),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (26, 2.0988866294877404),\n",
            "INFO:flwr:\t              (26, 2.0988866294877404),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (27, 2.1196454968153278),\n",
            "INFO:flwr:\t              (27, 2.1196454968153278),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (28, 2.1438667059931014),\n",
            "INFO:flwr:\t              (28, 2.1438667059931014),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (29, 2.191605544441218),\n",
            "INFO:flwr:\t              (29, 2.191605544441218),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (30, 2.230580830026116),\n",
            "INFO:flwr:\t              (30, 2.230580830026116),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (31, 2.2951896417855777),\n",
            "INFO:flwr:\t              (31, 2.2951896417855777),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (32, 2.3252523564917387),\n",
            "INFO:flwr:\t              (32, 2.3252523564917387),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (33, 2.306788202670115),\n",
            "INFO:flwr:\t              (33, 2.306788202670115),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (34, 2.3751305449705535),\n",
            "INFO:flwr:\t              (34, 2.3751305449705535),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (35, 2.3443573676880267),\n",
            "INFO:flwr:\t              (35, 2.3443573676880267),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (36, 2.524219707445546),\n",
            "INFO:flwr:\t              (36, 2.524219707445546),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (37, 2.4487152953387668),\n",
            "INFO:flwr:\t              (37, 2.4487152953387668),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (38, 2.514610880708106),\n",
            "INFO:flwr:\t              (38, 2.514610880708106),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (39, 2.7295863758107752),\n",
            "INFO:flwr:\t              (39, 2.7295863758107752),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (40, 2.6122243247427486)]}History (metrics, centralized):\n",
            "INFO:flwr:\t              (40, 2.6122243247427486)]}History (metrics, centralized):\n",
            "\u001b[92mINFO \u001b[0m:      \t{'Centralised report': [(0,\n",
            "INFO:flwr:\t{'Centralised report': [(0,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.94815   0.07082   0.13179      '\n",
            "INFO:flwr:\t                         '           0    0.94815   0.07082   0.13179      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.91417   0.99961   0.95498     '\n",
            "INFO:flwr:\t                         '           1    0.91417   0.99961   0.95498     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.91440     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.91440     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.93116   0.53521   0.54338     '\n",
            "INFO:flwr:\t                         '   macro avg    0.93116   0.53521   0.54338     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.91729   0.91440   0.87946     '\n",
            "INFO:flwr:\t                         'weighted avg    0.91729   0.91440   0.87946     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (1,\n",
            "INFO:flwr:\t                        (1,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.38736   0.54412   0.45255      '\n",
            "INFO:flwr:\t                         '           0    0.38736   0.54412   0.45255      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95199   0.91308   0.93213     '\n",
            "INFO:flwr:\t                         '           1    0.95199   0.91308   0.93213     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.87923     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.87923     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.66967   0.72860   0.69234     '\n",
            "INFO:flwr:\t                         '   macro avg    0.66967   0.72860   0.69234     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90019   0.87923   0.88813     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90019   0.87923   0.88813     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (2,\n",
            "INFO:flwr:\t                        (2,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.33489   0.42545   0.37478      '\n",
            "INFO:flwr:\t                         '           0    0.33489   0.42545   0.37478      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.94034   0.91465   0.92732     '\n",
            "INFO:flwr:\t                         '           1    0.94034   0.91465   0.92732     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.86977     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.86977     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.63762   0.67005   0.65105     '\n",
            "INFO:flwr:\t                         '   macro avg    0.63762   0.67005   0.65105     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.88479   0.86977   0.87663     '\n",
            "INFO:flwr:\t                         'weighted avg    0.88479   0.86977   0.87663     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (3,\n",
            "INFO:flwr:\t                        (3,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.42533   0.62047   0.50470      '\n",
            "INFO:flwr:\t                         '           0    0.42533   0.62047   0.50470      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95980   0.91532   0.93704     '\n",
            "INFO:flwr:\t                         '           1    0.95980   0.91532   0.93704     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88827     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88827     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.69257   0.76790   0.72087     '\n",
            "INFO:flwr:\t                         '   macro avg    0.69257   0.76790   0.72087     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.91077   0.88827   0.89737     '\n",
            "INFO:flwr:\t                         'weighted avg    0.91077   0.88827   0.89737     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (4,\n",
            "INFO:flwr:\t                        (4,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.40123   0.55934   0.46727      '\n",
            "INFO:flwr:\t                         '           0    0.40123   0.55934   0.46727      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95364   0.91569   0.93428     '\n",
            "INFO:flwr:\t                         '           1    0.95364   0.91569   0.93428     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88300     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88300     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.67744   0.73751   0.70078     '\n",
            "INFO:flwr:\t                         '   macro avg    0.67744   0.73751   0.70078     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90297   0.88300   0.89144     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90297   0.88300   0.89144     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (5,\n",
            "INFO:flwr:\t                        (5,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.40182   0.55726   0.46694      '\n",
            "INFO:flwr:\t                         '           0    0.40182   0.55726   0.46694      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95346   0.91620   0.93446     '\n",
            "INFO:flwr:\t                         '           1    0.95346   0.91620   0.93446     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88327     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88327     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.67764   0.73673   0.70070     '\n",
            "INFO:flwr:\t                         '   macro avg    0.67764   0.73673   0.70070     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90285   0.88327   0.89157     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90285   0.88327   0.89157     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (6,\n",
            "INFO:flwr:\t                        (6,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.39829   0.54869   0.46155      '\n",
            "INFO:flwr:\t                         '           0    0.39829   0.54869   0.46155      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95261   0.91627   0.93409     '\n",
            "INFO:flwr:\t                         '           1    0.95261   0.91627   0.93409     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88255     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88255     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.67545   0.73248   0.69782     '\n",
            "INFO:flwr:\t                         '   macro avg    0.67545   0.73248   0.69782     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90175   0.88255   0.89074     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90175   0.88255   0.89074     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (7,\n",
            "INFO:flwr:\t                        (7,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.40173   0.55920   0.46756      '\n",
            "INFO:flwr:\t                         '           0    0.40173   0.55920   0.46756      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95364   0.91588   0.93438     '\n",
            "INFO:flwr:\t                         '           1    0.95364   0.91588   0.93438     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88316     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88316     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.67768   0.73754   0.70097     '\n",
            "INFO:flwr:\t                         '   macro avg    0.67768   0.73754   0.70097     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90301   0.88316   0.89155     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90301   0.88316   0.89155     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (8,\n",
            "INFO:flwr:\t                        (8,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.40930   0.57732   0.47900      '\n",
            "INFO:flwr:\t                         '           0    0.40930   0.57732   0.47900      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95546   0.91584   0.93523     '\n",
            "INFO:flwr:\t                         '           1    0.95546   0.91584   0.93523     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88478     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88478     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.68238   0.74658   0.70712     '\n",
            "INFO:flwr:\t                         '   macro avg    0.68238   0.74658   0.70712     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90535   0.88478   0.89338     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90535   0.88478   0.89338     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (9,\n",
            "INFO:flwr:\t                        (9,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.41932   0.58008   0.48677      '\n",
            "INFO:flwr:\t                         '           0    0.41932   0.58008   0.48677      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95588   0.91886   0.93700     '\n",
            "INFO:flwr:\t                         '           1    0.95588   0.91886   0.93700     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88778     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88778     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.68760   0.74947   0.71189     '\n",
            "INFO:flwr:\t                         '   macro avg    0.68760   0.74947   0.71189     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90665   0.88778   0.89570     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90665   0.88778   0.89570     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (10,\n",
            "INFO:flwr:\t                        (10,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.40784   0.57261   0.47638      '\n",
            "INFO:flwr:\t                         '           0    0.40784   0.57261   0.47638      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95499   0.91602   0.93510     '\n",
            "INFO:flwr:\t                         '           1    0.95499   0.91602   0.93510     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88452     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88452     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.68142   0.74432   0.70574     '\n",
            "INFO:flwr:\t                         '   macro avg    0.68142   0.74432   0.70574     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90480   0.88452   0.89302     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90480   0.88452   0.89302     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (11,\n",
            "INFO:flwr:\t                        (11,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.41230   0.58396   0.48334      '\n",
            "INFO:flwr:\t                         '           0    0.41230   0.58396   0.48334      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95613   0.91593   0.93560     '\n",
            "INFO:flwr:\t                         '           1    0.95613   0.91593   0.93560     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88547     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88547     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.68422   0.74994   0.70947     '\n",
            "INFO:flwr:\t                         '   macro avg    0.68422   0.74994   0.70947     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90624   0.88547   0.89411     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90624   0.88547   0.89411     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (12,\n",
            "INFO:flwr:\t                        (12,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.42137   0.56404   0.48238      '\n",
            "INFO:flwr:\t                         '           0    0.42137   0.56404   0.48238      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95441   0.92176   0.93780     '\n",
            "INFO:flwr:\t                         '           1    0.95441   0.92176   0.93780     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88895     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88895     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.68789   0.74290   0.71009     '\n",
            "INFO:flwr:\t                         '   macro avg    0.68789   0.74290   0.71009     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90550   0.88895   0.89602     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90550   0.88895   0.89602     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (13,\n",
            "INFO:flwr:\t                        (13,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.42361   0.58409   0.49108      '\n",
            "INFO:flwr:\t                         '           0    0.42361   0.58409   0.49108      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95632   0.91973   0.93767     '\n",
            "INFO:flwr:\t                         '           1    0.95632   0.91973   0.93767     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.88893     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.88893     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.68997   0.75191   0.71437     '\n",
            "INFO:flwr:\t                         '   macro avg    0.68997   0.75191   0.71437     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90745   0.88893   0.89669     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90745   0.88893   0.89669     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (14,\n",
            "INFO:flwr:\t                        (14,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.43299   0.59115   0.49985      '\n",
            "INFO:flwr:\t                         '           0    0.43299   0.59115   0.49985      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95712   0.92181   0.93913     '\n",
            "INFO:flwr:\t                         '           1    0.95712   0.92181   0.93913     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.89147     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.89147     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.69505   0.75648   0.71949     '\n",
            "INFO:flwr:\t                         '   macro avg    0.69505   0.75648   0.71949     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.90904   0.89147   0.89883     '\n",
            "INFO:flwr:\t                         'weighted avg    0.90904   0.89147   0.89883     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (15,\n",
            "INFO:flwr:\t                        (15,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.90300   0.57815   0.70495      '\n",
            "INFO:flwr:\t                         '           0    0.90300   0.57815   0.70495      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95888   0.99373   0.97599     '\n",
            "INFO:flwr:\t                         '           1    0.95888   0.99373   0.97599     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95560     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95560     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.93094   0.78594   0.84047     '\n",
            "INFO:flwr:\t                         '   macro avg    0.93094   0.78594   0.84047     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.95376   0.95560   0.95113     '\n",
            "INFO:flwr:\t                         'weighted avg    0.95376   0.95560   0.95113     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (16,\n",
            "INFO:flwr:\t                        (16,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.98038   0.58755   0.73476      '\n",
            "INFO:flwr:\t                         '           0    0.98038   0.58755   0.73476      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95996   0.99881   0.97900     '\n",
            "INFO:flwr:\t                         '           1    0.95996   0.99881   0.97900     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96108     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96108     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97017   0.79318   0.85688     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97017   0.79318   0.85688     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96183   0.96108   0.95659     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96183   0.96108   0.95659     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (17,\n",
            "INFO:flwr:\t                        (17,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.98615   0.56141   0.71549      '\n",
            "INFO:flwr:\t                         '           0    0.98615   0.56141   0.71549      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95755   0.99920   0.97793     '\n",
            "INFO:flwr:\t                         '           1    0.95755   0.99920   0.97793     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95904     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95904     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97185   0.78031   0.84671     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97185   0.78031   0.84671     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96017   0.95904   0.95386     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96017   0.95904   0.95386     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (18,\n",
            "INFO:flwr:\t                        (18,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.98931   0.57607   0.72815      '\n",
            "INFO:flwr:\t                         '           0    0.98931   0.57607   0.72815      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95891   0.99937   0.97872     '\n",
            "INFO:flwr:\t                         '           1    0.95891   0.99937   0.97872     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96054     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96054     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97411   0.78772   0.85344     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97411   0.78772   0.85344     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96170   0.96054   0.95574     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96170   0.96054   0.95574     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (19,\n",
            "INFO:flwr:\t                        (19,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99009   0.56639   0.72057      '\n",
            "INFO:flwr:\t                         '           0    0.99009   0.56639   0.72057      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95802   0.99943   0.97828     '\n",
            "INFO:flwr:\t                         '           1    0.95802   0.99943   0.97828     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95970     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95970     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97405   0.78291   0.84943     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97405   0.78291   0.84943     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96096   0.95970   0.95464     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96096   0.95970   0.95464     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (20,\n",
            "INFO:flwr:\t                        (20,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99035   0.58216   0.73328      '\n",
            "INFO:flwr:\t                         '           0    0.99035   0.58216   0.73328      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95948   0.99943   0.97905     '\n",
            "INFO:flwr:\t                         '           1    0.95948   0.99943   0.97905     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96115     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96115     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97492   0.79079   0.85616     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97492   0.79079   0.85616     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96231   0.96115   0.95650     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96231   0.96115   0.95650     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (21,\n",
            "INFO:flwr:\t                        (21,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99207   0.58866   0.73889      '\n",
            "INFO:flwr:\t                         '           0    0.99207   0.58866   0.73889      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.96009   0.99953   0.97941     '\n",
            "INFO:flwr:\t                         '           1    0.96009   0.99953   0.97941     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96183     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96183     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97608   0.79409   0.85915     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97608   0.79409   0.85915     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96302   0.96183   0.95735     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96302   0.96183   0.95735     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (22,\n",
            "INFO:flwr:\t                        (22,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99288   0.57898   0.73143      '\n",
            "INFO:flwr:\t                         '           0    0.99288   0.57898   0.73143      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95919   0.99958   0.97897     '\n",
            "INFO:flwr:\t                         '           1    0.95919   0.99958   0.97897     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96099     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96099     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97604   0.78928   0.85520     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97604   0.78928   0.85520     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96228   0.96099   0.95626     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96228   0.96099   0.95626     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (23,\n",
            "INFO:flwr:\t                        (23,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99236   0.55685   0.71339      '\n",
            "INFO:flwr:\t                         '           0    0.99236   0.55685   0.71339      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95714   0.99957   0.97789     '\n",
            "INFO:flwr:\t                         '           1    0.95714   0.99957   0.97789     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95895     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95895     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97475   0.77821   0.84564     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97475   0.77821   0.84564     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96037   0.95895   0.95363     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96037   0.95895   0.95363     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (24,\n",
            "INFO:flwr:\t                        (24,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.98822   0.55712   0.71254      '\n",
            "INFO:flwr:\t                         '           0    0.98822   0.55712   0.71254      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95715   0.99933   0.97779     '\n",
            "INFO:flwr:\t                         '           1    0.95715   0.99933   0.97779     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95876     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95876     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97269   0.77823   0.84516     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97269   0.77823   0.84516     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96000   0.95876   0.95345     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96000   0.95876   0.95345     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (25,\n",
            "INFO:flwr:\t                        (25,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99532   0.55837   0.71540      '\n",
            "INFO:flwr:\t                         '           0    0.99532   0.55837   0.71540      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95729   0.99973   0.97805     '\n",
            "INFO:flwr:\t                         '           1    0.95729   0.99973   0.97805     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95924     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95924     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97630   0.77905   0.84672     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97630   0.77905   0.84672     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96077   0.95924   0.95395     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96077   0.95924   0.95395     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (26,\n",
            "INFO:flwr:\t                        (26,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99590   0.57095   0.72580      '\n",
            "INFO:flwr:\t                         '           0    0.99590   0.57095   0.72580      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95845   0.99976   0.97867     '\n",
            "INFO:flwr:\t                         '           1    0.95845   0.99976   0.97867     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96042     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96042     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97718   0.78536   0.85224     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97718   0.78536   0.85224     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96189   0.96042   0.95547     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96189   0.96042   0.95547     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (27,\n",
            "INFO:flwr:\t                        (27,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99573   0.58091   0.73375      '\n",
            "INFO:flwr:\t                         '           0    0.99573   0.58091   0.73375      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95938   0.99975   0.97915     '\n",
            "INFO:flwr:\t                         '           1    0.95938   0.99975   0.97915     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96132     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96132     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97756   0.79033   0.85645     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97756   0.79033   0.85645     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96271   0.96132   0.95663     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96271   0.96132   0.95663     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (28,\n",
            "INFO:flwr:\t                        (28,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99522   0.57580   0.72952      '\n",
            "INFO:flwr:\t                         '           0    0.99522   0.57580   0.72952      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95890   0.99972   0.97889     '\n",
            "INFO:flwr:\t                         '           1    0.95890   0.99972   0.97889     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96083     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96083     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97706   0.78776   0.85420     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97706   0.78776   0.85420     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96223   0.96083   0.95601     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96223   0.96083   0.95601     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (29,\n",
            "INFO:flwr:\t                        (29,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99564   0.56874   0.72394      '\n",
            "INFO:flwr:\t                         '           0    0.99564   0.56874   0.72394      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95825   0.99975   0.97856     '\n",
            "INFO:flwr:\t                         '           1    0.95825   0.99975   0.97856     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96021     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96021     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97694   0.78424   0.85125     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97694   0.78424   0.85125     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96168   0.96021   0.95520     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96168   0.96021   0.95520     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (30,\n",
            "INFO:flwr:\t                        (30,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99515   0.56791   0.72314      '\n",
            "INFO:flwr:\t                         '           0    0.99515   0.56791   0.72314      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95817   0.99972   0.97850     '\n",
            "INFO:flwr:\t                         '           1    0.95817   0.99972   0.97850     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.96011     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.96011     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97666   0.78382   0.85082     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97666   0.78382   0.85082     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96156   0.96011   0.95508     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96156   0.96011   0.95508     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (31,\n",
            "INFO:flwr:\t                        (31,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99487   0.56376   0.71970      '\n",
            "INFO:flwr:\t                         '           0    0.99487   0.56376   0.71970      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95778   0.99971   0.97830     '\n",
            "INFO:flwr:\t                         '           1    0.95778   0.99971   0.97830     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95971     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95971     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97633   0.78173   0.84900     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97633   0.78173   0.84900     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96119   0.95971   0.95457     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96119   0.95971   0.95457     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (32,\n",
            "INFO:flwr:\t                        (32,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99554   0.55519   0.71284      '\n",
            "INFO:flwr:\t                         '           0    0.99554   0.55519   0.71284      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95699   0.99975   0.97790     '\n",
            "INFO:flwr:\t                         '           1    0.95699   0.99975   0.97790     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95896     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95896     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97626   0.77747   0.84537     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97626   0.77747   0.84537     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96053   0.95896   0.95359     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96053   0.95896   0.95359     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (33,\n",
            "INFO:flwr:\t                        (33,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99425   0.55035   0.70851      '\n",
            "INFO:flwr:\t                         '           0    0.99425   0.55035   0.70851      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95654   0.99968   0.97763     '\n",
            "INFO:flwr:\t                         '           1    0.95654   0.99968   0.97763     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95846     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95846     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97540   0.77501   0.84307     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97540   0.77501   0.84307     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96000   0.95846   0.95294     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96000   0.95846   0.95294     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (34,\n",
            "INFO:flwr:\t                        (34,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99554   0.55533   0.71295      '\n",
            "INFO:flwr:\t                         '           0    0.99554   0.55533   0.71295      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95700   0.99975   0.97791     '\n",
            "INFO:flwr:\t                         '           1    0.95700   0.99975   0.97791     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95898     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95898     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97627   0.77754   0.84543     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97627   0.77754   0.84543     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96054   0.95898   0.95360     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96054   0.95898   0.95360     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (35,\n",
            "INFO:flwr:\t                        (35,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99436   0.56113   0.71742      '\n",
            "INFO:flwr:\t                         '           0    0.99436   0.56113   0.71742      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95754   0.99968   0.97816     '\n",
            "INFO:flwr:\t                         '           1    0.95754   0.99968   0.97816     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95945     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95945     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97595   0.78041   0.84779     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97595   0.78041   0.84779     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96092   0.95945   0.95424     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96092   0.95945   0.95424     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (36,\n",
            "INFO:flwr:\t                        (36,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99572   0.54675   0.70589      '\n",
            "INFO:flwr:\t                         '           0    0.99572   0.54675   0.70589      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95621   0.99976   0.97750     '\n",
            "INFO:flwr:\t                         '           1    0.95621   0.99976   0.97750     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95820     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95820     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97597   0.77326   0.84170     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97597   0.77326   0.84170     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.95984   0.95820   0.95259     '\n",
            "INFO:flwr:\t                         'weighted avg    0.95984   0.95820   0.95259     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (37,\n",
            "INFO:flwr:\t                        (37,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99524   0.54979   0.70830      '\n",
            "INFO:flwr:\t                         '           0    0.99524   0.54979   0.70830      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95649   0.99973   0.97764     '\n",
            "INFO:flwr:\t                         '           1    0.95649   0.99973   0.97764     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95846     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95846     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97587   0.77476   0.84297     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97587   0.77476   0.84297     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.96005   0.95846   0.95293     '\n",
            "INFO:flwr:\t                         'weighted avg    0.96005   0.95846   0.95293     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (38,\n",
            "INFO:flwr:\t                        (38,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.96535   0.55104   0.70159      '\n",
            "INFO:flwr:\t                         '           0    0.96535   0.55104   0.70159      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95654   0.99800   0.97683     '\n",
            "INFO:flwr:\t                         '           1    0.95654   0.99800   0.97683     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95700     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95700     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.96094   0.77452   0.83921     '\n",
            "INFO:flwr:\t                         '   macro avg    0.96094   0.77452   0.83921     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.95734   0.95700   0.95158     '\n",
            "INFO:flwr:\t                         'weighted avg    0.95734   0.95700   0.95158     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (39,\n",
            "INFO:flwr:\t                        (39,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.99645   0.54288   0.70284      '\n",
            "INFO:flwr:\t                         '           0    0.99645   0.54288   0.70284      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95586   0.99980   0.97734     '\n",
            "INFO:flwr:\t                         '           1    0.95586   0.99980   0.97734     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95789     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95789     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.97615   0.77134   0.84009     '\n",
            "INFO:flwr:\t                         '   macro avg    0.97615   0.77134   0.84009     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.95958   0.95789   0.95215     '\n",
            "INFO:flwr:\t                         'weighted avg    0.95958   0.95789   0.95215     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'),\n",
            "INFO:flwr:\t                         '78809\\n'),\n",
            "\u001b[92mINFO \u001b[0m:      \t                        (40,\n",
            "INFO:flwr:\t                        (40,\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '              precision    recall  f1-score   '\n",
            "INFO:flwr:\t                         '              precision    recall  f1-score   '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'support\\n'\n",
            "INFO:flwr:\t                         'support\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           0    0.95612   0.55450   0.70192      '\n",
            "INFO:flwr:\t                         '           0    0.95612   0.55450   0.70192      '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '7230\\n'\n",
            "INFO:flwr:\t                         '7230\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '           1    0.95683   0.99743   0.97671     '\n",
            "INFO:flwr:\t                         '           1    0.95683   0.99743   0.97671     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '71579\\n'\n",
            "INFO:flwr:\t                         '71579\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '\\n'\n",
            "INFO:flwr:\t                         '\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '    accuracy                        0.95679     '\n",
            "INFO:flwr:\t                         '    accuracy                        0.95679     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '   macro avg    0.95647   0.77596   0.83931     '\n",
            "INFO:flwr:\t                         '   macro avg    0.95647   0.77596   0.83931     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n'\n",
            "INFO:flwr:\t                         '78809\\n'\n",
            "\u001b[92mINFO \u001b[0m:      \t                         'weighted avg    0.95677   0.95679   0.95150     '\n",
            "INFO:flwr:\t                         'weighted avg    0.95677   0.95679   0.95150     '\n",
            "\u001b[92mINFO \u001b[0m:      \t                         '78809\\n')],\n",
            "INFO:flwr:\t                         '78809\\n')],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'accuracy': [(0, 0.9144006371498108),\n",
            "INFO:flwr:\t 'accuracy': [(0, 0.9144006371498108),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (1, 0.8792269825935364),\n",
            "INFO:flwr:\t              (1, 0.8792269825935364),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (2, 0.8697737455368042),\n",
            "INFO:flwr:\t              (2, 0.8697737455368042),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (3, 0.8882741928100586),\n",
            "INFO:flwr:\t              (3, 0.8882741928100586),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (4, 0.88299560546875),\n",
            "INFO:flwr:\t              (4, 0.88299560546875),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (5, 0.8832747340202332),\n",
            "INFO:flwr:\t              (5, 0.8832747340202332),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (6, 0.8825514912605286),\n",
            "INFO:flwr:\t              (6, 0.8825514912605286),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (7, 0.8831605315208435),\n",
            "INFO:flwr:\t              (7, 0.8831605315208435),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (8, 0.8847847580909729),\n",
            "INFO:flwr:\t              (8, 0.8847847580909729),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (9, 0.8877792954444885),\n",
            "INFO:flwr:\t              (9, 0.8877792954444885),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (10, 0.8845182657241821),\n",
            "INFO:flwr:\t              (10, 0.8845182657241821),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (11, 0.885469913482666),\n",
            "INFO:flwr:\t              (11, 0.885469913482666),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (12, 0.8889467120170593),\n",
            "INFO:flwr:\t              (12, 0.8889467120170593),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (13, 0.8889340162277222),\n",
            "INFO:flwr:\t              (13, 0.8889340162277222),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (14, 0.891471803188324),\n",
            "INFO:flwr:\t              (14, 0.891471803188324),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (15, 0.9556015133857727),\n",
            "INFO:flwr:\t              (15, 0.9556015133857727),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (16, 0.9610831141471863),\n",
            "INFO:flwr:\t              (16, 0.9610831141471863),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (17, 0.9590402245521545),\n",
            "INFO:flwr:\t              (17, 0.9590402245521545),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (18, 0.9605374932289124),\n",
            "INFO:flwr:\t              (18, 0.9605374932289124),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (19, 0.9597000479698181),\n",
            "INFO:flwr:\t              (19, 0.9597000479698181),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (20, 0.9611465930938721),\n",
            "INFO:flwr:\t              (20, 0.9611465930938721),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (21, 0.9618317484855652),\n",
            "INFO:flwr:\t              (21, 0.9618317484855652),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (22, 0.960994303226471),\n",
            "INFO:flwr:\t              (22, 0.960994303226471),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (23, 0.9589514136314392),\n",
            "INFO:flwr:\t              (23, 0.9589514136314392),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (24, 0.9587610363960266),\n",
            "INFO:flwr:\t              (24, 0.9587610363960266),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (25, 0.9592432379722595),\n",
            "INFO:flwr:\t              (25, 0.9592432379722595),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (26, 0.9604232907295227),\n",
            "INFO:flwr:\t              (26, 0.9604232907295227),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (27, 0.9613242149353027),\n",
            "INFO:flwr:\t              (27, 0.9613242149353027),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (28, 0.9608293175697327),\n",
            "INFO:flwr:\t              (28, 0.9608293175697327),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (29, 0.9602075815200806),\n",
            "INFO:flwr:\t              (29, 0.9602075815200806),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (30, 0.9601060748100281),\n",
            "INFO:flwr:\t              (30, 0.9601060748100281),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (31, 0.9597127437591553),\n",
            "INFO:flwr:\t              (31, 0.9597127437591553),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (32, 0.9589640498161316),\n",
            "INFO:flwr:\t              (32, 0.9589640498161316),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (33, 0.9584565162658691),\n",
            "INFO:flwr:\t              (33, 0.9584565162658691),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (34, 0.9589767456054688),\n",
            "INFO:flwr:\t              (34, 0.9589767456054688),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (35, 0.9594462513923645),\n",
            "INFO:flwr:\t              (35, 0.9594462513923645),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (36, 0.9582027196884155),\n",
            "INFO:flwr:\t              (36, 0.9582027196884155),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (37, 0.9584565162658691),\n",
            "INFO:flwr:\t              (37, 0.9584565162658691),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (38, 0.956997275352478),\n",
            "INFO:flwr:\t              (38, 0.956997275352478),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (39, 0.9578855037689209),\n",
            "INFO:flwr:\t              (39, 0.9578855037689209),\n",
            "\u001b[92mINFO \u001b[0m:      \t              (40, 0.956794261932373)],\n",
            "INFO:flwr:\t              (40, 0.956794261932373)],\n",
            "\u001b[92mINFO \u001b[0m:      \t 'loss': [(0, 0.5633272528648376),\n",
            "INFO:flwr:\t 'loss': [(0, 0.5633272528648376),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (1, 0.593224823474884),\n",
            "INFO:flwr:\t          (1, 0.593224823474884),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (2, 0.8698111176490784),\n",
            "INFO:flwr:\t          (2, 0.8698111176490784),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (3, 0.9248741269111633),\n",
            "INFO:flwr:\t          (3, 0.9248741269111633),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (4, 1.1406844854354858),\n",
            "INFO:flwr:\t          (4, 1.1406844854354858),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (5, 1.1973904371261597),\n",
            "INFO:flwr:\t          (5, 1.1973904371261597),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (6, 1.2157864570617676),\n",
            "INFO:flwr:\t          (6, 1.2157864570617676),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (7, 1.2410391569137573),\n",
            "INFO:flwr:\t          (7, 1.2410391569137573),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (8, 1.2876172065734863),\n",
            "INFO:flwr:\t          (8, 1.2876172065734863),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (9, 1.3448415994644165),\n",
            "INFO:flwr:\t          (9, 1.3448415994644165),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (10, 1.377259373664856),\n",
            "INFO:flwr:\t          (10, 1.377259373664856),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (11, 1.3616935014724731),\n",
            "INFO:flwr:\t          (11, 1.3616935014724731),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (12, 1.5094852447509766),\n",
            "INFO:flwr:\t          (12, 1.5094852447509766),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (13, 1.6048648357391357),\n",
            "INFO:flwr:\t          (13, 1.6048648357391357),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (14, 1.6292552947998047),\n",
            "INFO:flwr:\t          (14, 1.6292552947998047),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (15, 1.6762031316757202),\n",
            "INFO:flwr:\t          (15, 1.6762031316757202),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (16, 1.7921123504638672),\n",
            "INFO:flwr:\t          (16, 1.7921123504638672),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (17, 1.8987363576889038),\n",
            "INFO:flwr:\t          (17, 1.8987363576889038),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (18, 1.9275610446929932),\n",
            "INFO:flwr:\t          (18, 1.9275610446929932),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (19, 1.927960753440857),\n",
            "INFO:flwr:\t          (19, 1.927960753440857),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (20, 1.8559390306472778),\n",
            "INFO:flwr:\t          (20, 1.8559390306472778),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (21, 1.9612752199172974),\n",
            "INFO:flwr:\t          (21, 1.9612752199172974),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (22, 1.9139714241027832),\n",
            "INFO:flwr:\t          (22, 1.9139714241027832),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (23, 2.0630550384521484),\n",
            "INFO:flwr:\t          (23, 2.0630550384521484),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (24, 2.05899715423584),\n",
            "INFO:flwr:\t          (24, 2.05899715423584),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (25, 2.0931499004364014),\n",
            "INFO:flwr:\t          (25, 2.0931499004364014),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (26, 2.107858419418335),\n",
            "INFO:flwr:\t          (26, 2.107858419418335),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (27, 2.0857748985290527),\n",
            "INFO:flwr:\t          (27, 2.0857748985290527),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (28, 2.174936294555664),\n",
            "INFO:flwr:\t          (28, 2.174936294555664),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (29, 2.19726824760437),\n",
            "INFO:flwr:\t          (29, 2.19726824760437),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (30, 2.224874973297119),\n",
            "INFO:flwr:\t          (30, 2.224874973297119),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (31, 2.2805228233337402),\n",
            "INFO:flwr:\t          (31, 2.2805228233337402),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (32, 2.3319032192230225),\n",
            "INFO:flwr:\t          (32, 2.3319032192230225),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (33, 2.2670748233795166),\n",
            "INFO:flwr:\t          (33, 2.2670748233795166),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (34, 2.378068447113037),\n",
            "INFO:flwr:\t          (34, 2.378068447113037),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (35, 2.4169411659240723),\n",
            "INFO:flwr:\t          (35, 2.4169411659240723),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (36, 2.565579891204834),\n",
            "INFO:flwr:\t          (36, 2.565579891204834),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (37, 2.5098161697387695),\n",
            "INFO:flwr:\t          (37, 2.5098161697387695),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (38, 2.596853494644165),\n",
            "INFO:flwr:\t          (38, 2.596853494644165),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (39, 2.764934539794922),\n",
            "INFO:flwr:\t          (39, 2.764934539794922),\n",
            "\u001b[92mINFO \u001b[0m:      \t          (40, 2.746053457260132)]}\n",
            "INFO:flwr:\t          (40, 2.746053457260132)]}\n",
            "\u001b[92mINFO \u001b[0m:      \n",
            "INFO:flwr:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training started at: Fri Jun  7 18:03:16 2024\n",
            "Training finished at: Fri Jun  7 19:02:29 2024\n",
            "Simulation time: 3552.93 seconds\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "start_time = time.time()\n",
        "\n",
        "# Start simulation\n",
        "history = fl.simulation.start_simulation(\n",
        "    client_fn=client_fnc,\n",
        "    num_clients=NUM_CLIENTS,\n",
        "    config=fl.server.ServerConfig(num_rounds=40),\n",
        "    strategy=strategy,\n",
        "    client_resources={\"num_cpus\": 1, \"num_gpus\": 0},\n",
        "    ray_init_args={\n",
        "        \"num_cpus\": 1,\n",
        "        \"num_gpus\": 0,\n",
        "        \"_system_config\": {\"automatic_object_spilling_enabled\": False},\n",
        "    },\n",
        ")\n",
        "\n",
        "end_time = time.time()\n",
        "simulation_time = end_time - start_time\n",
        "\n",
        "# Print the results\n",
        "print(\"Training started at:\", time.ctime(start_time))\n",
        "print(\"Training finished at:\", time.ctime(end_time))\n",
        "print(f\"Simulation time: {simulation_time:.2f} seconds\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFnT-CsYmMNE"
      },
      "source": [
        "### 3 Clients for 40 local epochs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9YJjk6q9Vuc",
        "outputId": "f63745b7-f25f-4d1e-c9e1-551febbbf596"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.94815   0.07082   0.13179      7230\n",
            "           1    0.91417   0.99961   0.95498     71579\n",
            "\n",
            "    accuracy                        0.91440     78809\n",
            "   macro avg    0.93116   0.53521   0.54338     78809\n",
            "weighted avg    0.91729   0.91440   0.87946     78809\n",
            "\n",
            "1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.38736   0.54412   0.45255      7230\n",
            "           1    0.95199   0.91308   0.93213     71579\n",
            "\n",
            "    accuracy                        0.87923     78809\n",
            "   macro avg    0.66967   0.72860   0.69234     78809\n",
            "weighted avg    0.90019   0.87923   0.88813     78809\n",
            "\n",
            "2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.33489   0.42545   0.37478      7230\n",
            "           1    0.94034   0.91465   0.92732     71579\n",
            "\n",
            "    accuracy                        0.86977     78809\n",
            "   macro avg    0.63762   0.67005   0.65105     78809\n",
            "weighted avg    0.88479   0.86977   0.87663     78809\n",
            "\n",
            "3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.42533   0.62047   0.50470      7230\n",
            "           1    0.95980   0.91532   0.93704     71579\n",
            "\n",
            "    accuracy                        0.88827     78809\n",
            "   macro avg    0.69257   0.76790   0.72087     78809\n",
            "weighted avg    0.91077   0.88827   0.89737     78809\n",
            "\n",
            "4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.40123   0.55934   0.46727      7230\n",
            "           1    0.95364   0.91569   0.93428     71579\n",
            "\n",
            "    accuracy                        0.88300     78809\n",
            "   macro avg    0.67744   0.73751   0.70078     78809\n",
            "weighted avg    0.90297   0.88300   0.89144     78809\n",
            "\n",
            "5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.40182   0.55726   0.46694      7230\n",
            "           1    0.95346   0.91620   0.93446     71579\n",
            "\n",
            "    accuracy                        0.88327     78809\n",
            "   macro avg    0.67764   0.73673   0.70070     78809\n",
            "weighted avg    0.90285   0.88327   0.89157     78809\n",
            "\n",
            "6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.39829   0.54869   0.46155      7230\n",
            "           1    0.95261   0.91627   0.93409     71579\n",
            "\n",
            "    accuracy                        0.88255     78809\n",
            "   macro avg    0.67545   0.73248   0.69782     78809\n",
            "weighted avg    0.90175   0.88255   0.89074     78809\n",
            "\n",
            "7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.40173   0.55920   0.46756      7230\n",
            "           1    0.95364   0.91588   0.93438     71579\n",
            "\n",
            "    accuracy                        0.88316     78809\n",
            "   macro avg    0.67768   0.73754   0.70097     78809\n",
            "weighted avg    0.90301   0.88316   0.89155     78809\n",
            "\n",
            "8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.40930   0.57732   0.47900      7230\n",
            "           1    0.95546   0.91584   0.93523     71579\n",
            "\n",
            "    accuracy                        0.88478     78809\n",
            "   macro avg    0.68238   0.74658   0.70712     78809\n",
            "weighted avg    0.90535   0.88478   0.89338     78809\n",
            "\n",
            "9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.41932   0.58008   0.48677      7230\n",
            "           1    0.95588   0.91886   0.93700     71579\n",
            "\n",
            "    accuracy                        0.88778     78809\n",
            "   macro avg    0.68760   0.74947   0.71189     78809\n",
            "weighted avg    0.90665   0.88778   0.89570     78809\n",
            "\n",
            "10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.40784   0.57261   0.47638      7230\n",
            "           1    0.95499   0.91602   0.93510     71579\n",
            "\n",
            "    accuracy                        0.88452     78809\n",
            "   macro avg    0.68142   0.74432   0.70574     78809\n",
            "weighted avg    0.90480   0.88452   0.89302     78809\n",
            "\n",
            "11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.41230   0.58396   0.48334      7230\n",
            "           1    0.95613   0.91593   0.93560     71579\n",
            "\n",
            "    accuracy                        0.88547     78809\n",
            "   macro avg    0.68422   0.74994   0.70947     78809\n",
            "weighted avg    0.90624   0.88547   0.89411     78809\n",
            "\n",
            "12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.42137   0.56404   0.48238      7230\n",
            "           1    0.95441   0.92176   0.93780     71579\n",
            "\n",
            "    accuracy                        0.88895     78809\n",
            "   macro avg    0.68789   0.74290   0.71009     78809\n",
            "weighted avg    0.90550   0.88895   0.89602     78809\n",
            "\n",
            "13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.42361   0.58409   0.49108      7230\n",
            "           1    0.95632   0.91973   0.93767     71579\n",
            "\n",
            "    accuracy                        0.88893     78809\n",
            "   macro avg    0.68997   0.75191   0.71437     78809\n",
            "weighted avg    0.90745   0.88893   0.89669     78809\n",
            "\n",
            "14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.43299   0.59115   0.49985      7230\n",
            "           1    0.95712   0.92181   0.93913     71579\n",
            "\n",
            "    accuracy                        0.89147     78809\n",
            "   macro avg    0.69505   0.75648   0.71949     78809\n",
            "weighted avg    0.90904   0.89147   0.89883     78809\n",
            "\n",
            "15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.90300   0.57815   0.70495      7230\n",
            "           1    0.95888   0.99373   0.97599     71579\n",
            "\n",
            "    accuracy                        0.95560     78809\n",
            "   macro avg    0.93094   0.78594   0.84047     78809\n",
            "weighted avg    0.95376   0.95560   0.95113     78809\n",
            "\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.98038   0.58755   0.73476      7230\n",
            "           1    0.95996   0.99881   0.97900     71579\n",
            "\n",
            "    accuracy                        0.96108     78809\n",
            "   macro avg    0.97017   0.79318   0.85688     78809\n",
            "weighted avg    0.96183   0.96108   0.95659     78809\n",
            "\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.98615   0.56141   0.71549      7230\n",
            "           1    0.95755   0.99920   0.97793     71579\n",
            "\n",
            "    accuracy                        0.95904     78809\n",
            "   macro avg    0.97185   0.78031   0.84671     78809\n",
            "weighted avg    0.96017   0.95904   0.95386     78809\n",
            "\n",
            "18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.98931   0.57607   0.72815      7230\n",
            "           1    0.95891   0.99937   0.97872     71579\n",
            "\n",
            "    accuracy                        0.96054     78809\n",
            "   macro avg    0.97411   0.78772   0.85344     78809\n",
            "weighted avg    0.96170   0.96054   0.95574     78809\n",
            "\n",
            "19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99009   0.56639   0.72057      7230\n",
            "           1    0.95802   0.99943   0.97828     71579\n",
            "\n",
            "    accuracy                        0.95970     78809\n",
            "   macro avg    0.97405   0.78291   0.84943     78809\n",
            "weighted avg    0.96096   0.95970   0.95464     78809\n",
            "\n",
            "20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99035   0.58216   0.73328      7230\n",
            "           1    0.95948   0.99943   0.97905     71579\n",
            "\n",
            "    accuracy                        0.96115     78809\n",
            "   macro avg    0.97492   0.79079   0.85616     78809\n",
            "weighted avg    0.96231   0.96115   0.95650     78809\n",
            "\n",
            "21\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99207   0.58866   0.73889      7230\n",
            "           1    0.96009   0.99953   0.97941     71579\n",
            "\n",
            "    accuracy                        0.96183     78809\n",
            "   macro avg    0.97608   0.79409   0.85915     78809\n",
            "weighted avg    0.96302   0.96183   0.95735     78809\n",
            "\n",
            "22\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99288   0.57898   0.73143      7230\n",
            "           1    0.95919   0.99958   0.97897     71579\n",
            "\n",
            "    accuracy                        0.96099     78809\n",
            "   macro avg    0.97604   0.78928   0.85520     78809\n",
            "weighted avg    0.96228   0.96099   0.95626     78809\n",
            "\n",
            "23\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99236   0.55685   0.71339      7230\n",
            "           1    0.95714   0.99957   0.97789     71579\n",
            "\n",
            "    accuracy                        0.95895     78809\n",
            "   macro avg    0.97475   0.77821   0.84564     78809\n",
            "weighted avg    0.96037   0.95895   0.95363     78809\n",
            "\n",
            "24\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.98822   0.55712   0.71254      7230\n",
            "           1    0.95715   0.99933   0.97779     71579\n",
            "\n",
            "    accuracy                        0.95876     78809\n",
            "   macro avg    0.97269   0.77823   0.84516     78809\n",
            "weighted avg    0.96000   0.95876   0.95345     78809\n",
            "\n",
            "25\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99532   0.55837   0.71540      7230\n",
            "           1    0.95729   0.99973   0.97805     71579\n",
            "\n",
            "    accuracy                        0.95924     78809\n",
            "   macro avg    0.97630   0.77905   0.84672     78809\n",
            "weighted avg    0.96077   0.95924   0.95395     78809\n",
            "\n",
            "26\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99590   0.57095   0.72580      7230\n",
            "           1    0.95845   0.99976   0.97867     71579\n",
            "\n",
            "    accuracy                        0.96042     78809\n",
            "   macro avg    0.97718   0.78536   0.85224     78809\n",
            "weighted avg    0.96189   0.96042   0.95547     78809\n",
            "\n",
            "27\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99573   0.58091   0.73375      7230\n",
            "           1    0.95938   0.99975   0.97915     71579\n",
            "\n",
            "    accuracy                        0.96132     78809\n",
            "   macro avg    0.97756   0.79033   0.85645     78809\n",
            "weighted avg    0.96271   0.96132   0.95663     78809\n",
            "\n",
            "28\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99522   0.57580   0.72952      7230\n",
            "           1    0.95890   0.99972   0.97889     71579\n",
            "\n",
            "    accuracy                        0.96083     78809\n",
            "   macro avg    0.97706   0.78776   0.85420     78809\n",
            "weighted avg    0.96223   0.96083   0.95601     78809\n",
            "\n",
            "29\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99564   0.56874   0.72394      7230\n",
            "           1    0.95825   0.99975   0.97856     71579\n",
            "\n",
            "    accuracy                        0.96021     78809\n",
            "   macro avg    0.97694   0.78424   0.85125     78809\n",
            "weighted avg    0.96168   0.96021   0.95520     78809\n",
            "\n",
            "30\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99515   0.56791   0.72314      7230\n",
            "           1    0.95817   0.99972   0.97850     71579\n",
            "\n",
            "    accuracy                        0.96011     78809\n",
            "   macro avg    0.97666   0.78382   0.85082     78809\n",
            "weighted avg    0.96156   0.96011   0.95508     78809\n",
            "\n",
            "31\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99487   0.56376   0.71970      7230\n",
            "           1    0.95778   0.99971   0.97830     71579\n",
            "\n",
            "    accuracy                        0.95971     78809\n",
            "   macro avg    0.97633   0.78173   0.84900     78809\n",
            "weighted avg    0.96119   0.95971   0.95457     78809\n",
            "\n",
            "32\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99554   0.55519   0.71284      7230\n",
            "           1    0.95699   0.99975   0.97790     71579\n",
            "\n",
            "    accuracy                        0.95896     78809\n",
            "   macro avg    0.97626   0.77747   0.84537     78809\n",
            "weighted avg    0.96053   0.95896   0.95359     78809\n",
            "\n",
            "33\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99425   0.55035   0.70851      7230\n",
            "           1    0.95654   0.99968   0.97763     71579\n",
            "\n",
            "    accuracy                        0.95846     78809\n",
            "   macro avg    0.97540   0.77501   0.84307     78809\n",
            "weighted avg    0.96000   0.95846   0.95294     78809\n",
            "\n",
            "34\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99554   0.55533   0.71295      7230\n",
            "           1    0.95700   0.99975   0.97791     71579\n",
            "\n",
            "    accuracy                        0.95898     78809\n",
            "   macro avg    0.97627   0.77754   0.84543     78809\n",
            "weighted avg    0.96054   0.95898   0.95360     78809\n",
            "\n",
            "35\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99436   0.56113   0.71742      7230\n",
            "           1    0.95754   0.99968   0.97816     71579\n",
            "\n",
            "    accuracy                        0.95945     78809\n",
            "   macro avg    0.97595   0.78041   0.84779     78809\n",
            "weighted avg    0.96092   0.95945   0.95424     78809\n",
            "\n",
            "36\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99572   0.54675   0.70589      7230\n",
            "           1    0.95621   0.99976   0.97750     71579\n",
            "\n",
            "    accuracy                        0.95820     78809\n",
            "   macro avg    0.97597   0.77326   0.84170     78809\n",
            "weighted avg    0.95984   0.95820   0.95259     78809\n",
            "\n",
            "37\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99524   0.54979   0.70830      7230\n",
            "           1    0.95649   0.99973   0.97764     71579\n",
            "\n",
            "    accuracy                        0.95846     78809\n",
            "   macro avg    0.97587   0.77476   0.84297     78809\n",
            "weighted avg    0.96005   0.95846   0.95293     78809\n",
            "\n",
            "38\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.96535   0.55104   0.70159      7230\n",
            "           1    0.95654   0.99800   0.97683     71579\n",
            "\n",
            "    accuracy                        0.95700     78809\n",
            "   macro avg    0.96094   0.77452   0.83921     78809\n",
            "weighted avg    0.95734   0.95700   0.95158     78809\n",
            "\n",
            "39\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.99645   0.54288   0.70284      7230\n",
            "           1    0.95586   0.99980   0.97734     71579\n",
            "\n",
            "    accuracy                        0.95789     78809\n",
            "   macro avg    0.97615   0.77134   0.84009     78809\n",
            "weighted avg    0.95958   0.95789   0.95215     78809\n",
            "\n",
            "40\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.95612   0.55450   0.70192      7230\n",
            "           1    0.95683   0.99743   0.97671     71579\n",
            "\n",
            "    accuracy                        0.95679     78809\n",
            "   macro avg    0.95647   0.77596   0.83931     78809\n",
            "weighted avg    0.95677   0.95679   0.95150     78809\n",
            "\n"
          ]
        }
      ],
      "source": [
        "var = history.metrics_centralized['Centralised report']\n",
        "print(type(var))\n",
        "for i in var:\n",
        "  for pair in i:\n",
        "    print(pair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "The function below takes the accuracy and loss both of type list as an argument and\n",
        "plot them on two separate graphs.\n",
        "\"\"\"\n",
        "def figures(acc_values, loss_values):\n",
        "    plt.plot(acc_values)\n",
        "    plt.legend(['Accuracy'], loc = 'lower right')\n",
        "    plt.ylabel('Test Accuracy')\n",
        "    plt.xlabel('Rounds')\n",
        "    plt.title(f\"Accuracy curve: Federated learning with {NUM_CLIENTS} clients\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "b4rYTVUO9nsJ",
        "outputId": "5bd6b7d0-cfb4-4b2d-8dcf-b0750461065a"
      },
      "outputs": [],
      "source": [
        "accuracy = history.metrics_centralized['accuracy']\n",
        "acc_values = [item[1] for item in accuracy]\n",
        "loss = history.metrics_centralized['loss']\n",
        "loss_values = [item[1] for item in loss]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'NUM_CLIENTS' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m loss_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfigures\u001b[49m\u001b[43m(\u001b[49m\u001b[43macc_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_values\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[2], line 10\u001b[0m, in \u001b[0;36mfigures\u001b[1;34m(acc_values, loss_values)\u001b[0m\n\u001b[0;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRounds\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy curve: Federated learning with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mNUM_CLIENTS\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m clients\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'NUM_CLIENTS' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "loss_values = None\n",
        "NUM\n",
        "figures(acc_values, loss_values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "acc_values = [0.5211841464042664, 0.9560964107513428, 0.9566927552223206, 0.956794261932373, 0.9567181468009949, 0.9569211602210999, 0.9578601717948914, 0.9571495652198792, 0.957136869430542, 0.9579870104789734, 0.9578093886375427, 0.9610450863838196, 0.9610450863838196, 0.9619206190109253, 0.962922990322113, 0.9612988233566284, 0.9614891409873962, 0.9626946449279785, 0.9615399241447449, 0.9636970162391663, 0.9644837379455566, 0.9644457101821899, 0.9634559750556946, 0.9637097120285034, 0.9652197360992432, 0.9629610776901245, 0.9632909893989563, 0.9627453684806824, 0.9640396237373352, 0.9631894826889038, 0.9621363282203674, 0.9619079232215881, 0.9618825316429138, 0.9620601534843445, 0.9625169634819031, 0.9625804424285889, 0.963202178478241, 0.964026927947998, 0.964369535446167, 0.9643568396568298, 0.9644710421562195]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVSziN31-MUD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 965
        },
        "id": "z6tplKR8hY0O",
        "outputId": "4a8b2e70-8877-4d74-a8eb-d354539d3f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.11590077728033066, 0.936072587966919, 0.942799985408783, 0.9460256695747375, 0.9436279535293579, 0.9463878870010376, 0.9458186626434326, 0.9480611085891724, 0.9474229216575623, 0.9498205780982971, 0.9532532691955566, 0.9503898620605469, 0.9528220295906067, 0.9546160101890564, 0.9528048038482666, 0.9522528052330017, 0.9540295600891113, 0.950493335723877, 0.9531843066215515, 0.9518043398857117, 0.9490788578987122]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "accuracy3 = history.metrics_centralized['accuracy']\n",
        "acc_values3 = [item[1] for item in accuracy3]\n",
        "loss3 = history.metrics_centralized['loss']\n",
        "loss_values3 = [item[1] for item in loss3]\n",
        "print(acc_values3)\n",
        "figures(acc_values3, loss_values3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m14Fy1rnQiOh",
        "outputId": "2611e75e-ddec-4808-c42a-3fa45ceaef80"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.09419   0.58381   0.16220      6771\n",
            "           1    0.82390   0.25749   0.39236     51201\n",
            "\n",
            "    accuracy                        0.29561     57972\n",
            "   macro avg    0.45904   0.42065   0.27728     57972\n",
            "weighted avg    0.73867   0.29561   0.36548     57972\n",
            "\n",
            "1\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91061   0.35357   0.50936      6771\n",
            "           1    0.92091   0.99541   0.95671     51201\n",
            "\n",
            "    accuracy                        0.92044     57972\n",
            "   macro avg    0.91576   0.67449   0.73304     57972\n",
            "weighted avg    0.91971   0.92044   0.90446     57972\n",
            "\n",
            "2\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.90680   0.37218   0.52775      6771\n",
            "           1    0.92298   0.99494   0.95761     51201\n",
            "\n",
            "    accuracy                        0.92220     57972\n",
            "   macro avg    0.91489   0.68356   0.74268     57972\n",
            "weighted avg    0.92109   0.92220   0.90740     57972\n",
            "\n",
            "3\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.90735   0.36450   0.52007      6771\n",
            "           1    0.92212   0.99508   0.95721     51201\n",
            "\n",
            "    accuracy                        0.92143     57972\n",
            "   macro avg    0.91474   0.67979   0.73864     57972\n",
            "weighted avg    0.92040   0.92143   0.90615     57972\n",
            "\n",
            "4\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91182   0.36346   0.51975      6771\n",
            "           1    0.92202   0.99535   0.95729     51201\n",
            "\n",
            "    accuracy                        0.92155     57972\n",
            "   macro avg    0.91692   0.67941   0.73852     57972\n",
            "weighted avg    0.92083   0.92155   0.90618     57972\n",
            "\n",
            "5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91554   0.36981   0.52683      6771\n",
            "           1    0.92275   0.99549   0.95774     51201\n",
            "\n",
            "    accuracy                        0.92241     57972\n",
            "   macro avg    0.91915   0.68265   0.74228     57972\n",
            "weighted avg    0.92191   0.92241   0.90741     57972\n",
            "\n",
            "6\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91620   0.38429   0.54146      6771\n",
            "           1    0.92438   0.99535   0.95855     51201\n",
            "\n",
            "    accuracy                        0.92398     57972\n",
            "   macro avg    0.92029   0.68982   0.75001     57972\n",
            "weighted avg    0.92343   0.92398   0.90984     57972\n",
            "\n",
            "7\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91690   0.38621   0.54349      6771\n",
            "           1    0.92460   0.99537   0.95868     51201\n",
            "\n",
            "    accuracy                        0.92422     57972\n",
            "   macro avg    0.92075   0.69079   0.75109     57972\n",
            "weighted avg    0.92370   0.92422   0.91019     57972\n",
            "\n",
            "8\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91603   0.38827   0.54538      6771\n",
            "           1    0.92483   0.99529   0.95877     51201\n",
            "\n",
            "    accuracy                        0.92439     57972\n",
            "   macro avg    0.92043   0.69178   0.75207     57972\n",
            "weighted avg    0.92380   0.92439   0.91049     57972\n",
            "\n",
            "9\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91629   0.38798   0.54513      6771\n",
            "           1    0.92480   0.99531   0.95876     51201\n",
            "\n",
            "    accuracy                        0.92438     57972\n",
            "   macro avg    0.92054   0.69165   0.75195     57972\n",
            "weighted avg    0.92380   0.92438   0.91045     57972\n",
            "\n",
            "10\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91446   0.39315   0.54989      6771\n",
            "           1    0.92537   0.99514   0.95899     51201\n",
            "\n",
            "    accuracy                        0.92483     57972\n",
            "   macro avg    0.91992   0.69414   0.75444     57972\n",
            "weighted avg    0.92410   0.92483   0.91121     57972\n",
            "\n",
            "11\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91486   0.39359   0.55039      6771\n",
            "           1    0.92543   0.99516   0.95903     51201\n",
            "\n",
            "    accuracy                        0.92489     57972\n",
            "   macro avg    0.92014   0.69437   0.75471     57972\n",
            "weighted avg    0.92419   0.92489   0.91130     57972\n",
            "\n",
            "12\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91528   0.39891   0.55565      6771\n",
            "           1    0.92603   0.99512   0.95933     51201\n",
            "\n",
            "    accuracy                        0.92548     57972\n",
            "   macro avg    0.92066   0.69701   0.75749     57972\n",
            "weighted avg    0.92477   0.92548   0.91218     57972\n",
            "\n",
            "13\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91375   0.40053   0.55694      6771\n",
            "           1    0.92621   0.99500   0.95937     51201\n",
            "\n",
            "    accuracy                        0.92557     57972\n",
            "   macro avg    0.91998   0.69777   0.75815     57972\n",
            "weighted avg    0.92475   0.92557   0.91237     57972\n",
            "\n",
            "14\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91390   0.40600   0.56223      6771\n",
            "           1    0.92682   0.99494   0.95968     51201\n",
            "\n",
            "    accuracy                        0.92615     57972\n",
            "   macro avg    0.92036   0.70047   0.76095     57972\n",
            "weighted avg    0.92531   0.92615   0.91325     57972\n",
            "\n",
            "15\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91485   0.41412   0.57015      6771\n",
            "           1    0.92775   0.99490   0.96015     51201\n",
            "\n",
            "    accuracy                        0.92707     57972\n",
            "   macro avg    0.92130   0.70451   0.76515     57972\n",
            "weighted avg    0.92624   0.92707   0.91460     57972\n",
            "\n",
            "16\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91697   0.41427   0.57070      6771\n",
            "           1    0.92778   0.99504   0.96023     51201\n",
            "\n",
            "    accuracy                        0.92721     57972\n",
            "   macro avg    0.92237   0.70465   0.76547     57972\n",
            "weighted avg    0.92651   0.92721   0.91474     57972\n",
            "\n",
            "17\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.91836   0.42032   0.57670      6771\n",
            "           1    0.92847   0.99506   0.96061     51201\n",
            "\n",
            "    accuracy                        0.92793     57972\n",
            "   macro avg    0.92342   0.70769   0.76865     57972\n",
            "weighted avg    0.92729   0.92793   0.91577     57972\n",
            "\n",
            "18\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.92035   0.41811   0.57500      6771\n",
            "           1    0.92823   0.99521   0.96055     51201\n",
            "\n",
            "    accuracy                        0.92781     57972\n",
            "   macro avg    0.92429   0.70666   0.76778     57972\n",
            "weighted avg    0.92731   0.92781   0.91552     57972\n",
            "\n",
            "19\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.92067   0.42505   0.58159      6771\n",
            "           1    0.92902   0.99516   0.96095     51201\n",
            "\n",
            "    accuracy                        0.92857     57972\n",
            "   macro avg    0.92484   0.71010   0.77127     57972\n",
            "weighted avg    0.92804   0.92857   0.91664     57972\n",
            "\n",
            "20\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0    0.92148   0.41944   0.57647      6771\n",
            "           1    0.92838   0.99527   0.96067     51201\n",
            "\n",
            "    accuracy                        0.92802     57972\n",
            "   macro avg    0.92493   0.70735   0.76857     57972\n",
            "weighted avg    0.92758   0.92802   0.91579     57972\n",
            "\n"
          ]
        }
      ],
      "source": [
        "var2 = history.metrics_centralized['Centralised report']\n",
        "print(type(var2))\n",
        "for i in var2:\n",
        "  for pair in i:\n",
        "    print(pair)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
